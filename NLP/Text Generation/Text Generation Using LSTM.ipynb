{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dfc10e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\varsha\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "import emoji\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from keras import Sequential\n",
    "from keras.layers import InputLayer, Dense, SimpleRNN, Embedding\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import wordcloud\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "nlp= spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18d365bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_csv(r\"D:\\Datasets\\Poems_text_NWP_NLP\\poems-100.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83991171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O my Luve's like a red, red rose\\nThat’s newly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The rose is red,\\nThe violet's blue,\\nSugar is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How do I love thee? Let me count the ways.\\nI ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Had I the heavens' embroidered cloths,\\nEnwrou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I.\\n    Enough! we're tired, my heart and I.\\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  O my Luve's like a red, red rose\\nThat’s newly...\n",
       "1  The rose is red,\\nThe violet's blue,\\nSugar is...\n",
       "2  How do I love thee? Let me count the ways.\\nI ...\n",
       "3  Had I the heavens' embroidered cloths,\\nEnwrou...\n",
       "4  I.\\n    Enough! we're tired, my heart and I.\\n..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fa64d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f30d6631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the data\n",
    "def data_preprocess(text):\n",
    "    \n",
    "    # normalize the data\n",
    "    text= text.lower()\n",
    "\n",
    "    # remove links\n",
    "    text= re.sub(r'https?://\\S+', ' ', text)\n",
    "\n",
    "    # remove special characters\n",
    "    text= re.sub(r'[^a-zA-Z0-9]+', ' ', text)\n",
    "\n",
    "    # replace emoji with there meaning \n",
    "    text= emoji.demojize(text, delimiters= ',')\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbfa80b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e160fc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cleaned_text']= data['text'].apply(data_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f48ab085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O my Luve's like a red, red rose\\nThat’s newly...</td>\n",
       "      <td>o my luve s like a red red rose that s newly s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The rose is red,\\nThe violet's blue,\\nSugar is...</td>\n",
       "      <td>the rose is red the violet s blue sugar is swe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How do I love thee? Let me count the ways.\\nI ...</td>\n",
       "      <td>how do i love thee let me count the ways i lov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Had I the heavens' embroidered cloths,\\nEnwrou...</td>\n",
       "      <td>had i the heavens embroidered cloths enwrought...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I.\\n    Enough! we're tired, my heart and I.\\n...</td>\n",
       "      <td>i enough we re tired my heart and i we sit bes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>The city had withdrawn into itself\\nAnd left a...</td>\n",
       "      <td>the city had withdrawn into itself and left at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>O gift of God! O perfect day:\\n    Whereon...</td>\n",
       "      <td>o gift of god o perfect day whereon shall no ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>The world is too much with us; late and soon,\\...</td>\n",
       "      <td>the world is too much with us late and soon ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>To him who in the love of Nature holds\\nCo...</td>\n",
       "      <td>to him who in the love of nature holds commun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>It was an April morning: fresh and clear \\nThe...</td>\n",
       "      <td>it was an april morning fresh and clear the ri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  \\\n",
       "0   O my Luve's like a red, red rose\\nThat’s newly...   \n",
       "1   The rose is red,\\nThe violet's blue,\\nSugar is...   \n",
       "2   How do I love thee? Let me count the ways.\\nI ...   \n",
       "3   Had I the heavens' embroidered cloths,\\nEnwrou...   \n",
       "4   I.\\n    Enough! we're tired, my heart and I.\\n...   \n",
       "..                                                ...   \n",
       "95  The city had withdrawn into itself\\nAnd left a...   \n",
       "96      O gift of God! O perfect day:\\n    Whereon...   \n",
       "97  The world is too much with us; late and soon,\\...   \n",
       "98      To him who in the love of Nature holds\\nCo...   \n",
       "99  It was an April morning: fresh and clear \\nThe...   \n",
       "\n",
       "                                         cleaned_text  \n",
       "0   o my luve s like a red red rose that s newly s...  \n",
       "1   the rose is red the violet s blue sugar is swe...  \n",
       "2   how do i love thee let me count the ways i lov...  \n",
       "3   had i the heavens embroidered cloths enwrought...  \n",
       "4   i enough we re tired my heart and i we sit bes...  \n",
       "..                                                ...  \n",
       "95  the city had withdrawn into itself and left at...  \n",
       "96   o gift of god o perfect day whereon shall no ...  \n",
       "97  the world is too much with us late and soon ge...  \n",
       "98   to him who in the love of nature holds commun...  \n",
       "99  it was an april morning fresh and clear the ri...  \n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa3598c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper for tokenizing and stemming \n",
    "\n",
    "def stem_lemmatize(text):\n",
    "    \n",
    "    # for tokenizing the word\n",
    "    text= text.split()\n",
    "    \n",
    "    # lemmatize the word\n",
    "    lemma= WordNetLemmatizer()\n",
    "    text= [lemma.lemmatize(word) for word in text if word not in set(stopwords.words('english'))]\n",
    "    #concatenating the tokens into sentence\n",
    "    text= ' '.join(text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "481a67b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cleaned_text']= data['cleaned_text'].apply(stem_lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8330c4d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O my Luve's like a red, red rose\\nThat’s newly...</td>\n",
       "      <td>luve like red red rose newly sprung june luve ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The rose is red,\\nThe violet's blue,\\nSugar is...</td>\n",
       "      <td>rose red violet blue sugar sweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How do I love thee? Let me count the ways.\\nI ...</td>\n",
       "      <td>love thee let count way love thee depth breadt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Had I the heavens' embroidered cloths,\\nEnwrou...</td>\n",
       "      <td>heaven embroidered cloth enwrought golden silv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I.\\n    Enough! we're tired, my heart and I.\\n...</td>\n",
       "      <td>enough tired heart sit beside headstone thus w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>The city had withdrawn into itself\\nAnd left a...</td>\n",
       "      <td>city withdrawn left last country country whirl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>O gift of God! O perfect day:\\n    Whereon...</td>\n",
       "      <td>gift god perfect day whereon shall man work pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>The world is too much with us; late and soon,\\...</td>\n",
       "      <td>world much u late soon getting spending lay wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>To him who in the love of Nature holds\\nCo...</td>\n",
       "      <td>love nature hold communion visible form speaks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>It was an April morning: fresh and clear \\nThe...</td>\n",
       "      <td>april morning fresh clear rivulet delighting s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  \\\n",
       "0   O my Luve's like a red, red rose\\nThat’s newly...   \n",
       "1   The rose is red,\\nThe violet's blue,\\nSugar is...   \n",
       "2   How do I love thee? Let me count the ways.\\nI ...   \n",
       "3   Had I the heavens' embroidered cloths,\\nEnwrou...   \n",
       "4   I.\\n    Enough! we're tired, my heart and I.\\n...   \n",
       "..                                                ...   \n",
       "95  The city had withdrawn into itself\\nAnd left a...   \n",
       "96      O gift of God! O perfect day:\\n    Whereon...   \n",
       "97  The world is too much with us; late and soon,\\...   \n",
       "98      To him who in the love of Nature holds\\nCo...   \n",
       "99  It was an April morning: fresh and clear \\nThe...   \n",
       "\n",
       "                                         cleaned_text  \n",
       "0   luve like red red rose newly sprung june luve ...  \n",
       "1                    rose red violet blue sugar sweet  \n",
       "2   love thee let count way love thee depth breadt...  \n",
       "3   heaven embroidered cloth enwrought golden silv...  \n",
       "4   enough tired heart sit beside headstone thus w...  \n",
       "..                                                ...  \n",
       "95  city withdrawn left last country country whirl...  \n",
       "96  gift god perfect day whereon shall man work pl...  \n",
       "97  world much u late soon getting spending lay wa...  \n",
       "98  love nature hold communion visible form speaks...  \n",
       "99  april morning fresh clear rivulet delighting s...  \n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5632e358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"How do I love thee? Let me count the ways.\\nI love thee to the depth and breadth and height\\nMy soul can reach, when feeling out of sight\\nFor the ends of being and ideal grace.\\nI love thee to the level of every day's\\nMost quiet need, by sun and candle-light.\\nI love thee freely, as men strive for right.\\nI love thee purely, as they turn from praise.\\nI love thee with the passion put to use\\nIn my old griefs, and with my childhood's faith.\\nI love thee with a love I seemed to lose\\nWith my lost saints. I love with the breath,\\nSmiles, tears, of all my life; and, if God choose,\\nI shall but love thee better after death.\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f7fa49c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'love thee let count way love thee depth breadth height soul reach feeling sight end ideal grace love thee level every day quiet need sun candle light love thee freely men strive right love thee purely turn praise love thee passion put use old grief childhood faith love thee love seemed lose lost saint love breath smile tear life god choose shall love thee better death'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['cleaned_text'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ad18ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4484\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: 'one',\n",
       " 2: 'love',\n",
       " 3: 'shall',\n",
       " 4: 'know',\n",
       " 5: 'night',\n",
       " 6: 'like',\n",
       " 7: 'day',\n",
       " 8: 'heart',\n",
       " 9: 'see',\n",
       " 10: 'life',\n",
       " 11: 'thee',\n",
       " 12: 'yet',\n",
       " 13: 'come',\n",
       " 14: 'long',\n",
       " 15: 'man',\n",
       " 16: 'old',\n",
       " 17: 'thing',\n",
       " 18: 'time',\n",
       " 19: 'go',\n",
       " 20: 'would',\n",
       " 21: 'earth',\n",
       " 22: 'eye',\n",
       " 23: 'never',\n",
       " 24: 'sea',\n",
       " 25: 'men',\n",
       " 26: 'look',\n",
       " 27: 'hand',\n",
       " 28: 'thou',\n",
       " 29: 'well',\n",
       " 30: 'every',\n",
       " 31: 'ever',\n",
       " 32: 'sun',\n",
       " 33: 'thy',\n",
       " 34: 'little',\n",
       " 35: 'tree',\n",
       " 36: 'light',\n",
       " 37: 'god',\n",
       " 38: 'u',\n",
       " 39: 'voice',\n",
       " 40: 'good',\n",
       " 41: 'head',\n",
       " 42: 'let',\n",
       " 43: 'upon',\n",
       " 44: 'heaven',\n",
       " 45: 'take',\n",
       " 46: 'nothing',\n",
       " 47: 'stand',\n",
       " 48: 'death',\n",
       " 49: 'could',\n",
       " 50: 'young',\n",
       " 51: 'may',\n",
       " 52: 'star',\n",
       " 53: 'make',\n",
       " 54: 'woman',\n",
       " 55: 'sound',\n",
       " 56: 'wood',\n",
       " 57: 'still',\n",
       " 58: 'till',\n",
       " 59: 'sleep',\n",
       " 60: 'must',\n",
       " 61: 'say',\n",
       " 62: 'air',\n",
       " 63: 'sweet',\n",
       " 64: 'soul',\n",
       " 65: 'world',\n",
       " 66: 'child',\n",
       " 67: 'give',\n",
       " 68: 'word',\n",
       " 69: 'side',\n",
       " 70: 'far',\n",
       " 71: 'pas',\n",
       " 72: 'first',\n",
       " 73: 'back',\n",
       " 74: 'wind',\n",
       " 75: 'year',\n",
       " 76: 'white',\n",
       " 77: 'house',\n",
       " 78: 'face',\n",
       " 79: 'place',\n",
       " 80: 'tell',\n",
       " 81: 'rest',\n",
       " 82: 'grass',\n",
       " 83: 'turn',\n",
       " 84: 'half',\n",
       " 85: 'foot',\n",
       " 86: 'many',\n",
       " 87: 'much',\n",
       " 88: 'full',\n",
       " 89: 'away',\n",
       " 90: 'lost',\n",
       " 91: 'last',\n",
       " 92: 'arm',\n",
       " 93: 'think',\n",
       " 94: 'thought',\n",
       " 95: 'hear',\n",
       " 96: 'moon',\n",
       " 97: 'two',\n",
       " 98: 'round',\n",
       " 99: 'wild',\n",
       " 100: 'thousand',\n",
       " 101: 'dark',\n",
       " 102: 'enough',\n",
       " 103: 'sky',\n",
       " 104: 'walk',\n",
       " 105: 'new',\n",
       " 106: 'around',\n",
       " 107: 'cannot',\n",
       " 108: 'friend',\n",
       " 109: 'said',\n",
       " 110: 'alone',\n",
       " 111: 'cloud',\n",
       " 112: 'work',\n",
       " 113: 'great',\n",
       " 114: 'lie',\n",
       " 115: 'mine',\n",
       " 116: 'song',\n",
       " 117: 'always',\n",
       " 118: 'touch',\n",
       " 119: 'feel',\n",
       " 120: 'best',\n",
       " 121: 'joy',\n",
       " 122: 'three',\n",
       " 123: 'rise',\n",
       " 124: 'ride',\n",
       " 125: 'nature',\n",
       " 126: 'door',\n",
       " 127: 'laugh',\n",
       " 128: 'red',\n",
       " 129: 'tired',\n",
       " 130: 'blood',\n",
       " 131: 'loved',\n",
       " 132: 'close',\n",
       " 133: 'room',\n",
       " 134: 'le',\n",
       " 135: 'whose',\n",
       " 136: 'summer',\n",
       " 137: 'whole',\n",
       " 138: 'city',\n",
       " 139: 'made',\n",
       " 140: 'fire',\n",
       " 141: 'fill',\n",
       " 142: 'find',\n",
       " 143: 'call',\n",
       " 144: 'green',\n",
       " 145: 'fall',\n",
       " 146: 'mother',\n",
       " 147: 'body',\n",
       " 148: 'bird',\n",
       " 149: 'rock',\n",
       " 150: 'put',\n",
       " 151: 'name',\n",
       " 152: 'bright',\n",
       " 153: 'moment',\n",
       " 154: 'breast',\n",
       " 155: 'might',\n",
       " 156: 'hold',\n",
       " 157: 'wait',\n",
       " 158: 'bed',\n",
       " 159: 'dead',\n",
       " 160: 'hair',\n",
       " 161: 'deep',\n",
       " 162: 'blue',\n",
       " 163: 'reach',\n",
       " 164: 'dream',\n",
       " 165: 'keep',\n",
       " 166: 'leave',\n",
       " 167: 'large',\n",
       " 168: 'field',\n",
       " 169: 'saw',\n",
       " 170: 'spirit',\n",
       " 171: 'beat',\n",
       " 172: 'flower',\n",
       " 173: 'along',\n",
       " 174: 'toward',\n",
       " 175: 'water',\n",
       " 176: 'without',\n",
       " 177: 'age',\n",
       " 178: 'show',\n",
       " 179: 'lip',\n",
       " 180: 'limb',\n",
       " 181: 'play',\n",
       " 182: 'dear',\n",
       " 183: 'breath',\n",
       " 184: 'sit',\n",
       " 185: 'fly',\n",
       " 186: 'though',\n",
       " 187: 'even',\n",
       " 188: 'black',\n",
       " 189: 'vain',\n",
       " 190: 'past',\n",
       " 191: 'beautiful',\n",
       " 192: 'die',\n",
       " 193: 'live',\n",
       " 194: 'grow',\n",
       " 195: 'bring',\n",
       " 196: 'spring',\n",
       " 197: 'gone',\n",
       " 198: 'also',\n",
       " 199: 'mouth',\n",
       " 200: 'morning',\n",
       " 201: 'crowd',\n",
       " 202: 'help',\n",
       " 203: 'fair',\n",
       " 204: 'end',\n",
       " 205: 'spread',\n",
       " 206: 'wish',\n",
       " 207: 'stone',\n",
       " 208: 'since',\n",
       " 209: 'near',\n",
       " 210: 'lay',\n",
       " 211: 'done',\n",
       " 212: 'music',\n",
       " 213: 'youth',\n",
       " 214: 'open',\n",
       " 215: 'part',\n",
       " 216: 'blow',\n",
       " 217: 'leaf',\n",
       " 218: 'stop',\n",
       " 219: 'heard',\n",
       " 220: 'guess',\n",
       " 221: 'snow',\n",
       " 222: 'home',\n",
       " 223: 'sail',\n",
       " 224: 'within',\n",
       " 225: 'ground',\n",
       " 226: 'rose',\n",
       " 227: 'art',\n",
       " 228: 'grief',\n",
       " 229: 'smile',\n",
       " 230: 'ti',\n",
       " 231: 'soft',\n",
       " 232: 'mind',\n",
       " 233: 'follow',\n",
       " 234: 'beyond',\n",
       " 235: 'high',\n",
       " 236: 'free',\n",
       " 237: 'land',\n",
       " 238: 'low',\n",
       " 239: 'behind',\n",
       " 240: 'poet',\n",
       " 241: 'something',\n",
       " 242: 'short',\n",
       " 243: 'came',\n",
       " 244: 'hour',\n",
       " 245: 'soon',\n",
       " 246: 'become',\n",
       " 247: 'form',\n",
       " 248: 'talk',\n",
       " 249: 'boy',\n",
       " 250: 'cut',\n",
       " 251: 'neck',\n",
       " 252: 'forth',\n",
       " 253: 'dry',\n",
       " 254: 'way',\n",
       " 255: 'right',\n",
       " 256: 'faith',\n",
       " 257: 'tear',\n",
       " 258: 'better',\n",
       " 259: 'tread',\n",
       " 260: 'thus',\n",
       " 261: 'seem',\n",
       " 262: 'looking',\n",
       " 263: 'kiss',\n",
       " 264: 'lean',\n",
       " 265: 'pleasure',\n",
       " 266: 'break',\n",
       " 267: 'er',\n",
       " 268: 'path',\n",
       " 269: 'bosom',\n",
       " 270: 'gray',\n",
       " 271: 'gave',\n",
       " 272: 'brain',\n",
       " 273: 'sick',\n",
       " 274: 'sing',\n",
       " 275: 'girl',\n",
       " 276: 'else',\n",
       " 277: 'people',\n",
       " 278: 'seen',\n",
       " 279: 'early',\n",
       " 280: 'lover',\n",
       " 281: 'race',\n",
       " 282: 'hath',\n",
       " 283: 'plea',\n",
       " 284: 'believe',\n",
       " 285: 'hundred',\n",
       " 286: 'ear',\n",
       " 287: 'born',\n",
       " 288: 'root',\n",
       " 289: 'horse',\n",
       " 290: 'clear',\n",
       " 291: 'graf',\n",
       " 292: 'object',\n",
       " 293: 'roll',\n",
       " 294: 'fast',\n",
       " 295: 'press',\n",
       " 296: 'ship',\n",
       " 297: 'small',\n",
       " 298: 'luve',\n",
       " 299: 'ten',\n",
       " 300: 'need',\n",
       " 301: 'use',\n",
       " 302: 'true',\n",
       " 303: 'watch',\n",
       " 304: 'happy',\n",
       " 305: 'loose',\n",
       " 306: 'shade',\n",
       " 307: 'mean',\n",
       " 308: 'shadow',\n",
       " 309: 'yellow',\n",
       " 310: 'cross',\n",
       " 311: 'sharp',\n",
       " 312: 'thro',\n",
       " 313: 'fear',\n",
       " 314: 'least',\n",
       " 315: 'fail',\n",
       " 316: 'beneath',\n",
       " 317: 'went',\n",
       " 318: 'slave',\n",
       " 319: 'note',\n",
       " 320: 'street',\n",
       " 321: 'lake',\n",
       " 322: 'winter',\n",
       " 323: 'oh',\n",
       " 324: 'ring',\n",
       " 325: 'shake',\n",
       " 326: 'slow',\n",
       " 327: 'annabel',\n",
       " 328: 'lee',\n",
       " 329: 'beam',\n",
       " 330: 'deck',\n",
       " 331: 'space',\n",
       " 332: 'others',\n",
       " 333: 'growing',\n",
       " 334: 'tongue',\n",
       " 335: 'shore',\n",
       " 336: 'left',\n",
       " 337: 'silent',\n",
       " 338: 'brother',\n",
       " 339: 'sister',\n",
       " 340: 'stuff',\n",
       " 341: 'babe',\n",
       " 342: 'among',\n",
       " 343: 'whether',\n",
       " 344: 'ball',\n",
       " 345: 'behold',\n",
       " 346: 'person',\n",
       " 347: 'wife',\n",
       " 348: 'clock',\n",
       " 349: 'son',\n",
       " 350: 'finger',\n",
       " 351: 'cry',\n",
       " 352: 'run',\n",
       " 353: 'mile',\n",
       " 354: 'grace',\n",
       " 355: 'lose',\n",
       " 356: 'beside',\n",
       " 357: 'hard',\n",
       " 358: 'book',\n",
       " 359: 'fancy',\n",
       " 360: 'doubt',\n",
       " 361: 'wave',\n",
       " 362: 'hope',\n",
       " 363: 'return',\n",
       " 364: 'self',\n",
       " 365: 'alive',\n",
       " 366: 'gain',\n",
       " 367: 'beach',\n",
       " 368: 'together',\n",
       " 369: 'loving',\n",
       " 370: 'shine',\n",
       " 371: 'flesh',\n",
       " 372: 'fade',\n",
       " 373: 'bear',\n",
       " 374: 'present',\n",
       " 375: 'felt',\n",
       " 376: 'flag',\n",
       " 377: 'bone',\n",
       " 378: 'lead',\n",
       " 379: 'strong',\n",
       " 380: 'prove',\n",
       " 381: 'lift',\n",
       " 382: 'gold',\n",
       " 383: 'hollow',\n",
       " 384: 'late',\n",
       " 385: 'cold',\n",
       " 386: 'making',\n",
       " 387: 'friendly',\n",
       " 388: 'ago',\n",
       " 389: 'bride',\n",
       " 390: 'dying',\n",
       " 391: 'forever',\n",
       " 392: 'friendship',\n",
       " 393: 'whoever',\n",
       " 394: 'ask',\n",
       " 395: 'thine',\n",
       " 396: 'speak',\n",
       " 397: 'trust',\n",
       " 398: 'perfect',\n",
       " 399: 'hill',\n",
       " 400: 'posse',\n",
       " 401: 'cent',\n",
       " 402: 'war',\n",
       " 403: 'curious',\n",
       " 404: 'bare',\n",
       " 405: 'beard',\n",
       " 406: 'taken',\n",
       " 407: 'roof',\n",
       " 408: 'living',\n",
       " 409: 'country',\n",
       " 410: 'ready',\n",
       " 411: 'stretch',\n",
       " 412: 'mountain',\n",
       " 413: 'clothes',\n",
       " 414: 'stream',\n",
       " 415: 'cool',\n",
       " 416: 'river',\n",
       " 417: 'march',\n",
       " 418: 'start',\n",
       " 419: 'branch',\n",
       " 420: 'waiting',\n",
       " 421: 'human',\n",
       " 422: 'tale',\n",
       " 423: 'captain',\n",
       " 424: 'perhaps',\n",
       " 425: 'farewell',\n",
       " 426: 'christmas',\n",
       " 427: 'sand',\n",
       " 428: 'fare',\n",
       " 429: 'feeling',\n",
       " 430: 'cloth',\n",
       " 431: 'knife',\n",
       " 432: 'hang',\n",
       " 433: 'sat',\n",
       " 434: 'none',\n",
       " 435: 'brought',\n",
       " 436: 'power',\n",
       " 437: 'meet',\n",
       " 438: 'calm',\n",
       " 439: 'refuse',\n",
       " 440: 'wing',\n",
       " 441: 'maid',\n",
       " 442: 'breathe',\n",
       " 443: 'hush',\n",
       " 444: 'line',\n",
       " 445: 'sign',\n",
       " 446: 'chain',\n",
       " 447: 'four',\n",
       " 448: 'crowded',\n",
       " 449: 'april',\n",
       " 450: 'big',\n",
       " 451: 'seems',\n",
       " 452: 'million',\n",
       " 453: 'wise',\n",
       " 454: 'set',\n",
       " 455: 'delicate',\n",
       " 456: 'moving',\n",
       " 457: 'poem',\n",
       " 458: 'different',\n",
       " 459: 'strange',\n",
       " 460: 'wonder',\n",
       " 461: 'waist',\n",
       " 462: 'reason',\n",
       " 463: 'lock',\n",
       " 464: 'key',\n",
       " 465: 'kingdom',\n",
       " 466: 'lived',\n",
       " 467: 'shut',\n",
       " 468: 'course',\n",
       " 469: 'briar',\n",
       " 470: 'putting',\n",
       " 471: 'ocean',\n",
       " 472: 'ah',\n",
       " 473: 'mad',\n",
       " 474: 'powder',\n",
       " 475: 'shot',\n",
       " 476: 'broken',\n",
       " 477: 'hate',\n",
       " 478: 'echo',\n",
       " 479: 'tone',\n",
       " 480: 'pain',\n",
       " 481: 'passing',\n",
       " 482: 'embrace',\n",
       " 483: 'rising',\n",
       " 484: 'listen',\n",
       " 485: 'urge',\n",
       " 486: 'equal',\n",
       " 487: 'certain',\n",
       " 488: 'becomes',\n",
       " 489: 'cover',\n",
       " 490: 'battle',\n",
       " 491: 'next',\n",
       " 492: 'knowledge',\n",
       " 493: 'brown',\n",
       " 494: 'lord',\n",
       " 495: 'forward',\n",
       " 496: 'outward',\n",
       " 497: 'birth',\n",
       " 498: 'hat',\n",
       " 499: 'boot',\n",
       " 500: 'top',\n",
       " 501: 'corpse',\n",
       " 502: 'speech',\n",
       " 503: 'fresh',\n",
       " 504: 'dog',\n",
       " 505: 'gun',\n",
       " 506: 'thick',\n",
       " 507: 'skin',\n",
       " 508: 'week',\n",
       " 509: 'north',\n",
       " 510: 'twenty',\n",
       " 511: 'stay',\n",
       " 512: 'yard',\n",
       " 513: 'toss',\n",
       " 514: 'distant',\n",
       " 515: 'purpose',\n",
       " 516: 'drop',\n",
       " 517: 'mark',\n",
       " 518: 'step',\n",
       " 519: 'rain',\n",
       " 520: 'minute',\n",
       " 521: 'move',\n",
       " 522: 'holding',\n",
       " 523: 'change',\n",
       " 524: 'single',\n",
       " 525: 'walking',\n",
       " 526: 'comrade',\n",
       " 527: 'hero',\n",
       " 528: 'wear',\n",
       " 529: 'flow',\n",
       " 530: 'writing',\n",
       " 531: 'aware',\n",
       " 532: 'rich',\n",
       " 533: 'given',\n",
       " 534: 'tight',\n",
       " 535: 'accept',\n",
       " 536: 'fetch',\n",
       " 537: 'another',\n",
       " 538: 'whatever',\n",
       " 539: 'brook',\n",
       " 540: 'cause',\n",
       " 541: 'ascend',\n",
       " 542: 'flame',\n",
       " 543: 'desire',\n",
       " 544: 'speeding',\n",
       " 545: 'eve',\n",
       " 546: 'waste',\n",
       " 547: 'gentle',\n",
       " 548: 'understand',\n",
       " 549: 'shalt',\n",
       " 550: 'nightingale',\n",
       " 551: 'melancholy',\n",
       " 552: 'grove',\n",
       " 553: 'tune',\n",
       " 554: 'depth',\n",
       " 555: 'sight',\n",
       " 556: 'level',\n",
       " 557: 'strive',\n",
       " 558: 'seemed',\n",
       " 559: 'golden',\n",
       " 560: 'silver',\n",
       " 561: 'poor',\n",
       " 562: 'wet',\n",
       " 563: 'quick',\n",
       " 564: 'try',\n",
       " 565: 'scarcely',\n",
       " 566: 'care',\n",
       " 567: 'rough',\n",
       " 568: 'beauty',\n",
       " 569: 'express',\n",
       " 570: 'dwelling',\n",
       " 571: 'brow',\n",
       " 572: 'glow',\n",
       " 573: 'peace',\n",
       " 574: 'fame',\n",
       " 575: 'noon',\n",
       " 576: 'across',\n",
       " 577: 'apart',\n",
       " 578: 'beating',\n",
       " 579: 'length',\n",
       " 580: 'avail',\n",
       " 581: 'balance',\n",
       " 582: 'bow',\n",
       " 583: 'evening',\n",
       " 584: 'began',\n",
       " 585: 'riding',\n",
       " 586: 'rush',\n",
       " 587: 'either',\n",
       " 588: 'vast',\n",
       " 589: 'heave',\n",
       " 590: 'rhyme',\n",
       " 591: 'strain',\n",
       " 592: 'fit',\n",
       " 593: 'eternity',\n",
       " 594: 'throat',\n",
       " 595: 'king',\n",
       " 596: 'foolish',\n",
       " 597: 'meadow',\n",
       " 598: 'hurry',\n",
       " 599: 'wall',\n",
       " 600: 'gay',\n",
       " 601: 'real',\n",
       " 602: 'almost',\n",
       " 603: 'park',\n",
       " 604: 'lying',\n",
       " 605: 'lamp',\n",
       " 606: 'floating',\n",
       " 607: 'took',\n",
       " 608: 'dance',\n",
       " 609: 'remember',\n",
       " 610: 'fog',\n",
       " 611: 'whisper',\n",
       " 612: 'blind',\n",
       " 613: 'swift',\n",
       " 614: 'clean',\n",
       " 615: 'evil',\n",
       " 616: 'neither',\n",
       " 617: 'hot',\n",
       " 618: 'eternal',\n",
       " 619: 'holly',\n",
       " 620: 'bloom',\n",
       " 621: 'blossom',\n",
       " 622: 'scorn',\n",
       " 623: 'hell',\n",
       " 624: 'swear',\n",
       " 625: 'glass',\n",
       " 626: 'piece',\n",
       " 627: 'sad',\n",
       " 628: 'oft',\n",
       " 629: 'gazing',\n",
       " 630: 'carry',\n",
       " 631: 'sure',\n",
       " 632: 'strike',\n",
       " 633: 'loafe',\n",
       " 634: 'thirty',\n",
       " 635: 'begin',\n",
       " 636: 'cease',\n",
       " 637: 'creed',\n",
       " 638: 'school',\n",
       " 639: 'bad',\n",
       " 640: 'taste',\n",
       " 641: 'bank',\n",
       " 642: 'naked',\n",
       " 643: 'smoke',\n",
       " 644: 'thread',\n",
       " 645: 'color',\n",
       " 646: 'delight',\n",
       " 647: 'reckon',\n",
       " 648: 'second',\n",
       " 649: 'advance',\n",
       " 650: 'unseen',\n",
       " 651: 'leaving',\n",
       " 652: 'plenty',\n",
       " 653: 'scream',\n",
       " 654: 'road',\n",
       " 655: 'nation',\n",
       " 656: 'dinner',\n",
       " 657: 'loss',\n",
       " 658: 'idle',\n",
       " 659: 'bend',\n",
       " 660: 'want',\n",
       " 661: 'shirt',\n",
       " 662: 'held',\n",
       " 663: 'limitless',\n",
       " 664: 'fence',\n",
       " 665: 'weed',\n",
       " 666: 'answer',\n",
       " 667: 'broad',\n",
       " 668: 'known',\n",
       " 669: 'really',\n",
       " 670: 'hasten',\n",
       " 671: 'contain',\n",
       " 672: 'silently',\n",
       " 673: 'faced',\n",
       " 674: 'floor',\n",
       " 675: 'inside',\n",
       " 676: 'borne',\n",
       " 677: 'slight',\n",
       " 678: 'wandering',\n",
       " 679: 'father',\n",
       " 680: 'drest',\n",
       " 681: 'outside',\n",
       " 682: 'log',\n",
       " 683: 'eight',\n",
       " 684: 'belly',\n",
       " 685: 'heat',\n",
       " 686: 'swing',\n",
       " 687: 'wherever',\n",
       " 688: 'slowly',\n",
       " 689: 'consider',\n",
       " 690: 'law',\n",
       " 691: 'going',\n",
       " 692: 'boat',\n",
       " 693: 'travel',\n",
       " 694: 'sweat',\n",
       " 695: 'train',\n",
       " 696: 'season',\n",
       " 697: 'month',\n",
       " 698: 'cannon',\n",
       " 699: 'surface',\n",
       " 700: 'dusk',\n",
       " 701: 'hunter',\n",
       " 702: 'bush',\n",
       " 703: 'myriad',\n",
       " 704: 'mechanic',\n",
       " 705: 'prisoner',\n",
       " 706: 'egg',\n",
       " 707: 'common',\n",
       " 708: 'unknown',\n",
       " 709: 'greatest',\n",
       " 710: 'murmur',\n",
       " 711: 'astonish',\n",
       " 712: 'strength',\n",
       " 713: 'stick',\n",
       " 714: 'universe',\n",
       " 715: 'greater',\n",
       " 716: 'hurt',\n",
       " 717: 'sympathy',\n",
       " 718: 'list',\n",
       " 719: 'modern',\n",
       " 720: 'told',\n",
       " 721: 'term',\n",
       " 722: 'church',\n",
       " 723: 'nest',\n",
       " 724: 'fibre',\n",
       " 725: 'wheat',\n",
       " 726: 'send',\n",
       " 727: 'gloom',\n",
       " 728: 'dirt',\n",
       " 729: 'approaching',\n",
       " 730: 'guard',\n",
       " 731: 'glide',\n",
       " 732: 'wider',\n",
       " 733: 'bitter',\n",
       " 734: 'taking',\n",
       " 735: 'pasture',\n",
       " 736: 'desert',\n",
       " 737: 'perpetual',\n",
       " 738: 'sin',\n",
       " 739: 'row',\n",
       " 740: 'shaped',\n",
       " 741: 'breeze',\n",
       " 742: 'countenance',\n",
       " 743: 'bull',\n",
       " 744: 'square',\n",
       " 745: 'pick',\n",
       " 746: 'fighting',\n",
       " 747: 'darkness',\n",
       " 748: 'dull',\n",
       " 749: 'forget',\n",
       " 750: 'growth',\n",
       " 751: 'worth',\n",
       " 752: 'interest',\n",
       " 753: 'sullen',\n",
       " 754: 'died',\n",
       " 755: 'farther',\n",
       " 756: 'dollar',\n",
       " 757: 'aweary',\n",
       " 758: 'forgive',\n",
       " 759: 'share',\n",
       " 760: 'june',\n",
       " 761: 'gang',\n",
       " 762: 'violet',\n",
       " 763: 'sugar',\n",
       " 764: 'count',\n",
       " 765: 'height',\n",
       " 766: 'quiet',\n",
       " 767: 'candle',\n",
       " 768: 'freely',\n",
       " 769: 'dim',\n",
       " 770: 'tenderly',\n",
       " 771: 'straight',\n",
       " 772: 'sunset',\n",
       " 773: 'fold',\n",
       " 774: 'warm',\n",
       " 775: 'sigh',\n",
       " 776: 'pretty',\n",
       " 777: 'cheek',\n",
       " 778: 'estate',\n",
       " 779: 'master',\n",
       " 780: 'outlet',\n",
       " 781: 'firm',\n",
       " 782: 'morrow',\n",
       " 783: 'parting',\n",
       " 784: 'speed',\n",
       " 785: 'scented',\n",
       " 786: 'farm',\n",
       " 787: 'written',\n",
       " 788: 'pride',\n",
       " 789: 'claim',\n",
       " 790: 'bent',\n",
       " 791: 'pity',\n",
       " 792: 'western',\n",
       " 793: 'drew',\n",
       " 794: 'already',\n",
       " 795: 'worst',\n",
       " 796: 'alike',\n",
       " 797: 'proved',\n",
       " 798: 'crown',\n",
       " 799: 'pace',\n",
       " 800: 'nearer',\n",
       " 801: 'yonder',\n",
       " 802: 'burn',\n",
       " 803: 'grown',\n",
       " 804: 'fine',\n",
       " 805: 'glory',\n",
       " 806: 'shuddering',\n",
       " 807: 'kind',\n",
       " 808: 'gathered',\n",
       " 809: 'drawn',\n",
       " 810: 'wake',\n",
       " 811: 'dawn',\n",
       " 812: 'empty',\n",
       " 813: 'bench',\n",
       " 814: 'circle',\n",
       " 815: 'swan',\n",
       " 816: 'thin',\n",
       " 817: 'cup',\n",
       " 818: 'dew',\n",
       " 819: 'mist',\n",
       " 820: 'curtain',\n",
       " 821: 'watching',\n",
       " 822: 'swept',\n",
       " 823: 'maiden',\n",
       " 824: 'chilling',\n",
       " 825: 'bore',\n",
       " 826: 'sepulchre',\n",
       " 827: 'angel',\n",
       " 828: 'killing',\n",
       " 829: 'wiser',\n",
       " 830: 'tide',\n",
       " 831: 'darling',\n",
       " 832: 'gather',\n",
       " 833: 'ye',\n",
       " 834: 'higher',\n",
       " 835: 'getting',\n",
       " 836: 'worse',\n",
       " 837: 'lovely',\n",
       " 838: 'bud',\n",
       " 839: 'decline',\n",
       " 840: 'chance',\n",
       " 841: 'st',\n",
       " 842: 'scent',\n",
       " 843: 'crack',\n",
       " 844: 'frost',\n",
       " 845: 'plain',\n",
       " 846: 'prayer',\n",
       " 847: 'despair',\n",
       " 848: 'rowing',\n",
       " 849: 'swallow',\n",
       " 850: 'rank',\n",
       " 851: 'pike',\n",
       " 852: 'carried',\n",
       " 853: 'glad',\n",
       " 854: 'midnight',\n",
       " 855: 'knew',\n",
       " 856: 'bunch',\n",
       " 857: 'plant',\n",
       " 858: 'pluck',\n",
       " 859: 'grave',\n",
       " 860: 'assume',\n",
       " 861: 'parent',\n",
       " 862: 'health',\n",
       " 863: 'perfume',\n",
       " 864: 'hay',\n",
       " 865: 'barn',\n",
       " 866: 'reaching',\n",
       " 867: 'bough',\n",
       " 868: 'meeting',\n",
       " 869: 'learn',\n",
       " 870: 'proud',\n",
       " 871: 'get',\n",
       " 872: 'feed',\n",
       " 873: 'beginning',\n",
       " 874: 'lack',\n",
       " 875: 'proof',\n",
       " 876: 'bathe',\n",
       " 877: 'welcome',\n",
       " 878: 'organ',\n",
       " 879: 'inch',\n",
       " 880: 'fellow',\n",
       " 881: 'ahead',\n",
       " 882: 'dress',\n",
       " 883: 'folk',\n",
       " 884: 'game',\n",
       " 885: 'witness',\n",
       " 886: 'hip',\n",
       " 887: 'creation',\n",
       " 888: 'mossy',\n",
       " 889: 'worm',\n",
       " 890: 'elder',\n",
       " 891: 'offspring',\n",
       " 892: 'lap',\n",
       " 893: 'perceive',\n",
       " 894: 'translate',\n",
       " 895: 'wash',\n",
       " 896: 'immortal',\n",
       " 897: 'aside',\n",
       " 898: 'bloody',\n",
       " 899: 'driver',\n",
       " 900: 'litter',\n",
       " 901: 'enemy',\n",
       " 902: 'sudden',\n",
       " 903: 'oath',\n",
       " 904: 'quickly',\n",
       " 905: 'buried',\n",
       " 906: 'wagon',\n",
       " 907: 'pack',\n",
       " 908: 'leg',\n",
       " 909: 'seize',\n",
       " 910: 'spot',\n",
       " 911: 'kill',\n",
       " 912: 'falling',\n",
       " 913: 'yankee',\n",
       " 914: 'sparkle',\n",
       " 915: 'shout',\n",
       " 916: 'boatman',\n",
       " 917: 'stopt',\n",
       " 918: 'trapper',\n",
       " 919: 'west',\n",
       " 920: 'moccasin',\n",
       " 921: 'shoulder',\n",
       " 922: 'curl',\n",
       " 923: 'coarse',\n",
       " 924: 'motion',\n",
       " 925: 'twig',\n",
       " 926: 'enter',\n",
       " 927: 'ankle',\n",
       " 928: 'table',\n",
       " 929: 'hide',\n",
       " 930: 'handsome',\n",
       " 931: 'window',\n",
       " 932: 'lady',\n",
       " 933: 'splash',\n",
       " 934: 'stock',\n",
       " 935: 'float',\n",
       " 936: 'market',\n",
       " 937: 'enjoying',\n",
       " 938: 'main',\n",
       " 939: 'overhand',\n",
       " 940: 'hammer',\n",
       " 941: 'block',\n",
       " 942: 'tied',\n",
       " 943: 'drive',\n",
       " 944: 'steady',\n",
       " 945: 'band',\n",
       " 946: 'glance',\n",
       " 947: 'forehead',\n",
       " 948: 'leafy',\n",
       " 949: 'print',\n",
       " 950: 'playing',\n",
       " 951: 'bay',\n",
       " 952: 'listening',\n",
       " 953: 'prairie',\n",
       " 954: 'brood',\n",
       " 955: 'cattle',\n",
       " 956: 'eat',\n",
       " 957: 'sings',\n",
       " 958: 'plank',\n",
       " 959: 'retreat',\n",
       " 960: 'wheel',\n",
       " 961: 'surgeon',\n",
       " 962: 'gate',\n",
       " 963: 'keeper',\n",
       " 964: 'gentleman',\n",
       " 965: 'musical',\n",
       " 966: 'stray',\n",
       " 967: 'fish',\n",
       " 968: 'fourth',\n",
       " 969: 'grain',\n",
       " 970: 'towards',\n",
       " 971: 'cotton',\n",
       " 972: 'torch',\n",
       " 973: 'supper',\n",
       " 974: 'grandson',\n",
       " 975: 'joint',\n",
       " 976: 'fleet',\n",
       " 977: 'drink',\n",
       " 978: 'meat',\n",
       " 979: 'teacher',\n",
       " 980: 'hue',\n",
       " 981: 'sailor',\n",
       " 982: 'priest',\n",
       " 983: 'riddle',\n",
       " 984: 'globe',\n",
       " 985: 'conquer',\n",
       " 986: 'vessel',\n",
       " 987: 'meal',\n",
       " 988: 'natural',\n",
       " 989: 'wicked',\n",
       " 990: 'invited',\n",
       " 991: 'solid',\n",
       " 992: 'content',\n",
       " 993: 'chant',\n",
       " 994: 'sake',\n",
       " 995: 'resign',\n",
       " 996: 'question',\n",
       " 997: 'account',\n",
       " 998: 'drinking',\n",
       " 999: 'dumb',\n",
       " 1000: 'preparation',\n",
       " ...}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting text to numerical format\n",
    "\n",
    "# define the tokenizer object\n",
    "tokenizer= Tokenizer()\n",
    "\n",
    "# fitting tokenizer on the data --> get unique index for each word in the corpus \n",
    "tokenizer.fit_on_texts(data['cleaned_text'])\n",
    "\n",
    "\n",
    "# check the dictionary \n",
    "print(len(set(tokenizer.index_word)))\n",
    "tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce72a053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[298, 6, 128, 128, 226, 1078, 1785, 760, 298, 6, 1786, 1787, 181, 553, 203, 227, 28, 1788, 1789, 161, 298, 298, 11, 57, 182, 58, 24, 761, 253, 58, 24, 761, 253, 182, 149, 1790, 1791, 32, 298, 11, 57, 182, 427, 10, 3, 352, 428, 11, 29, 298, 428, 11, 29, 13, 298, 1079, 299, 100, 353]\n"
     ]
    }
   ],
   "source": [
    "# convert the text sentences into sequences of words using the vocabulary created the code \n",
    "# for converting the sentences into the sequence of text is as given.\n",
    "\n",
    "sentences= tokenizer.texts_to_sequences(data['cleaned_text'])\n",
    "print(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20066f9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'luve like red red rose newly sprung june luve like melodie sweetly play tune fair art thou bonnie lass deep luve luve thee still dear till sea gang dry till sea gang dry dear rock melt wi sun luve thee still dear sand life shall run fare thee well luve fare thee well come luve tho ten thousand mile'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['cleaned_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a1d49a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the vocabulary size\n",
    "vocab_size= len(tokenizer.index_word)+1   # 0 is reserved for padding so that’s why we added 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a83a9717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4485"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b163d8c6",
   "metadata": {},
   "source": [
    "At this point we have the dataset converted into numbers now it’s time to convert the data into x and y using the method discussed above means we have x the current word and y the next word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f0b46c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= []\n",
    "\n",
    "for sent in sentences:\n",
    "    for i in range(1, len(sent)):\n",
    "        \n",
    "        seq= sent[i-1:i+1]\n",
    "        data.append(seq)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d867090a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[298, 6],\n",
       " [6, 128],\n",
       " [128, 128],\n",
       " [128, 226],\n",
       " [226, 1078],\n",
       " [1078, 1785],\n",
       " [1785, 760],\n",
       " [760, 298],\n",
       " [298, 6],\n",
       " [6, 1786]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the data is a list of lists where the inner list has the first entry x and the second entry y.\n",
    "data[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da179b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12486"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca028922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data into X and y\n",
    "\n",
    "# convert list into array\n",
    "data_array= np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "30a345c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12486, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 298,    6],\n",
       "       [   6,  128],\n",
       "       [ 128,  128],\n",
       "       ...,\n",
       "       [ 143,  151],\n",
       "       [ 151, 1784],\n",
       "       [1784, 1075]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data_array.shape)\n",
    "data_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d65834c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert it into X and y\n",
    "\n",
    "X, y= data_array[:, 0], data_array[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6d54c4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 298,    6,  128, ...,  143,  151, 1784])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "70b9dc03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   6,  128,  128, ...,  151, 1784, 1075])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f3278ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the ouputs into the one hot vector over all the unique words\n",
    "y= to_categorical(y, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db21cb6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\varsha\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 1, 2)              8970      \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100)               41200     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4485)              452985    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 503155 (1.92 MB)\n",
      "Trainable params: 503155 (1.92 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 2, input_length= 1))\n",
    "# this line of code mean creating LSTM with 100 cell/neuron with each cell/neuron has its \n",
    "# own forget gate input gate and output gate\n",
    "model.add(keras.layers.LSTM(100))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(Dense(vocab_size, activation= 'softmax'))\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d1dab32b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\varsha\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d99ccd98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n",
      "WARNING:tensorflow:From C:\\Users\\varsha\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\varsha\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "391/391 [==============================] - 4s 5ms/step - loss: 8.2042 - accuracy: 0.0056\n",
      "Epoch 2/45\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 7.7934 - accuracy: 0.0070\n",
      "Epoch 3/45\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 7.6997 - accuracy: 0.0070\n",
      "Epoch 4/45\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 7.6384 - accuracy: 0.0070\n",
      "Epoch 5/45\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 7.5899 - accuracy: 0.0070\n",
      "Epoch 6/45\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 7.5512 - accuracy: 0.0070\n",
      "Epoch 7/45\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 7.5168 - accuracy: 0.0070\n",
      "Epoch 8/45\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 7.4871 - accuracy: 0.0073\n",
      "Epoch 9/45\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 7.4563 - accuracy: 0.0070\n",
      "Epoch 10/45\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 7.4317 - accuracy: 0.0072\n",
      "Epoch 11/45\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 7.4071 - accuracy: 0.0070\n",
      "Epoch 12/45\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 7.3848 - accuracy: 0.0070\n",
      "Epoch 13/45\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 7.3632 - accuracy: 0.0070\n",
      "Epoch 14/45\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 7.3446 - accuracy: 0.0075\n",
      "Epoch 15/45\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 7.3238 - accuracy: 0.0072\n",
      "Epoch 16/45\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 7.3033 - accuracy: 0.0077\n",
      "Epoch 17/45\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 7.2787 - accuracy: 0.0080\n",
      "Epoch 18/45\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 7.2534 - accuracy: 0.0082\n",
      "Epoch 19/45\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 7.2216 - accuracy: 0.0090\n",
      "Epoch 20/45\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 7.1827 - accuracy: 0.0089\n",
      "Epoch 21/45\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 7.1321 - accuracy: 0.0094\n",
      "Epoch 22/45\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 7.0679 - accuracy: 0.0096\n",
      "Epoch 23/45\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 7.0004 - accuracy: 0.0099\n",
      "Epoch 24/45\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 6.9438 - accuracy: 0.0119\n",
      "Epoch 25/45\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 6.8948 - accuracy: 0.0148\n",
      "Epoch 26/45\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 6.8512 - accuracy: 0.0143\n",
      "Epoch 27/45\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 6.8113 - accuracy: 0.0159\n",
      "Epoch 28/45\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 6.7736 - accuracy: 0.0163\n",
      "Epoch 29/45\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 6.7421 - accuracy: 0.0161\n",
      "Epoch 30/45\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 6.7166 - accuracy: 0.0171\n",
      "Epoch 31/45\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 6.6895 - accuracy: 0.0188\n",
      "Epoch 32/45\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 6.6629 - accuracy: 0.0194\n",
      "Epoch 33/45\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 6.6415 - accuracy: 0.0196\n",
      "Epoch 34/45\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 6.6215 - accuracy: 0.0187\n",
      "Epoch 35/45\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 6.6045 - accuracy: 0.0190\n",
      "Epoch 36/45\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 6.5843 - accuracy: 0.0197\n",
      "Epoch 37/45\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 6.5623 - accuracy: 0.0215\n",
      "Epoch 38/45\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 6.5505 - accuracy: 0.0230\n",
      "Epoch 39/45\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 6.5337 - accuracy: 0.0203\n",
      "Epoch 40/45\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 6.5114 - accuracy: 0.0224\n",
      "Epoch 41/45\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 6.4984 - accuracy: 0.0225\n",
      "Epoch 42/45\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 6.4813 - accuracy: 0.0240\n",
      "Epoch 43/45\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 6.4665 - accuracy: 0.0237\n",
      "Epoch 44/45\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 6.4490 - accuracy: 0.0252\n",
      "Epoch 45/45\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 6.4405 - accuracy: 0.0249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x16536174110>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training and evaluation\n",
    "model.fit(X, y, epochs= 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e604b5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, tokenizer, enter_text, n_pred):\n",
    "    \n",
    "    input_text, result= enter_text, enter_text\n",
    "#     print(input_text, result)\n",
    "    \n",
    "    for i in range(n_pred):\n",
    "        \n",
    "        encoded= tokenizer.texts_to_sequences([input_text])[0]\n",
    "        encoded= np.array(encoded)\n",
    "        \n",
    "        predict= model.predict(encoded, verbose= 0)\n",
    "        y_pred= np.argmax(predict, axis= 1)\n",
    "        out_word= ''\n",
    "        \n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index==y_pred:\n",
    "                out_word= word\n",
    "                break\n",
    "                \n",
    "    # append to input\n",
    "    input_text, result= out_word, result+' '+out_word\n",
    "            \n",
    "    return result\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5a949bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "love love\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, tokenizer, 'love', 13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cc9e1ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = keras.layers.Input(shape=(None, 256))\n",
    "encoder = keras.layers.LSTM(100, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dc12b3cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'lstm_4')>,\n",
       " <KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'lstm_4')>,\n",
       " <KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'lstm_4')>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_outputs, state_h, state_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121bdc96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f1e1c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb571bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58226227",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba74138c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
