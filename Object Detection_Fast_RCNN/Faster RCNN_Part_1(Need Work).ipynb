{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6564fe44",
   "metadata": {},
   "source": [
    "## Fast-RCNN\n",
    "\n",
    "Fast R-CNN is an extension of the R-CNN (Region-based Convolutional Neural Network) object detection algorithm, which aims to address some of the limitations of the original R-CNN in terms of speed and efficiency. \n",
    "\n",
    "Fast R-CNN introduces several improvements to the R-CNN pipeline, including the use of a single network for both region proposal and object detection, as well as the use of a region of interest (RoI) pooling layer to efficiently extract features from proposed regions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafe0f04",
   "metadata": {},
   "source": [
    "### Steps for Fast-RCNN:\n",
    "\n",
    "1. Preprocessing: Load and preprocess the input image.\n",
    "\n",
    "2. Feature Extraction: Pass the preprocessed image through a pre-trained CNN to extract feature maps.\n",
    "\n",
    "\n",
    "3. Region Proposal: Use a region proposal network (RPN) or an external method (e.g., selective search) to generate region proposals based on the feature maps.\n",
    "\n",
    "4. RoI Pooling: Apply RoI pooling to the feature maps to extract fixed-size features for each proposed region.\n",
    "\n",
    "5. Classification and Regression: Pass the RoI-pooled features through fully connected layers for object classification and bounding box regression.\n",
    "\n",
    "6. Non-Maximum Suppression: Apply non-maximum suppression to filter out redundant detections and produce the final set of object detections.\n",
    "\n",
    "7. Post-processing: Optionally, perform additional post-processing steps such as filtering detections based on confidence scores or applying additional heuristics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a397e9",
   "metadata": {},
   "source": [
    "#### Implementing Fast-RCNN using Tensorflow Object Detection API\n",
    "\n",
    "Steps for Fast-RCNN implementation:\n",
    "\n",
    "1. Install TensorFlow Object Detection API: First, you need to install the TensorFlow Object Detection API by following the installation instructions provided in the official documentation.\n",
    "\n",
    "2. Download Pre-trained Model: Download a pre-trained Fast R-CNN model checkpoint from the TensorFlow Model Zoo. The Model Zoo provides pre-trained models for various object detection architectures, including Fast R-CNN.\n",
    "\n",
    "3. Set Up Pipeline Configuration: Configure the object detection pipeline by creating a pipeline configuration file. This file specifies parameters such as the model architecture, input image size, class labels, and paths to the pre-trained model checkpoint and label map.\n",
    "\n",
    "4. Load Pre-trained Model: Load the pre-trained Fast R-CNN model checkpoint and instantiate the object detection model using TensorFlow's Object Detection API.\n",
    "\n",
    "5. Perform Inference: Use the loaded model to perform inference on input images or video frames. The model will detect objects in the input images and classify them into predefined classes.\n",
    "\n",
    "6. Visualize Results: Visualize the detected objects and their bounding boxes on the input images or video frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d88b249",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from object_detection.utils import visualization_utils as vis_utils\n",
    "matplotlib.use('TkAgg')  # or 'Qt5Agg'\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed64f7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_boxes(image, boxes, classes, scores, class_names, score_thresh=0.5):\n",
    "    fig, ax = plt.subplots(1, figsize=(12, 12))\n",
    "    ax.imshow(image)\n",
    "    \n",
    "#     for box, cls, score in zip(boxes, classes, scores):\n",
    "#         if score > 0.5:  # Filter out detections with low confidence\n",
    "#             ymin, xmin, ymax, xmax = box\n",
    "#             xmin = int(xmin * image_rgb.shape[1])\n",
    "#             xmax = int(xmax * image_rgb.shape[1])\n",
    "#             ymin = int(ymin * image_rgb.shape[0])\n",
    "#             ymax = int(ymax * image_rgb.shape[0])\n",
    "#             cv2.rectangle(image_rgb, (xmin, ymin), (xmax, ymax), (255, 0, 0), 2)\n",
    "#             cv2.putText(image_rgb, f'Class: {cls}, Score: {score:.2f}', (xmin, ymin - 10),\n",
    "#                         cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "\n",
    "    for box, cls, score in zip(boxes, classes, scores):\n",
    "        if score >= score_thresh:\n",
    "            ymin, xmin, ymax, xmax = box\n",
    "            height, width = ymax - ymin, xmax - xmin\n",
    "            rect = plt.Rectangle((xmin, ymin), width, height, fill=False, edgecolor='red', linewidth=2)\n",
    "            print(rect)\n",
    "            ax.add_patch(rect)\n",
    "            class_name = class_names[cls]\n",
    "            ax.text(xmin, ymin - 5, f'{class_name} {score:.2f}', bbox=dict(facecolor='red', alpha=0.5), fontsize=12, color='white')\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5fa9f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths for the model and label map\n",
    "PATH_TO_MODEL_DIR = r\"D:\\Transfer Learning Model\\Faster RCNN\\faster_rcnn_inception_resnet_v2_640x640_coco17_tpu-8\\faster_rcnn_inception_resnet_v2_640x640_coco17_tpu-8\\saved_model\"\n",
    "PATH_TO_LABELS = r\"D:\\Transfer Learning Model\\Labels\\imagenet.shortnames.list\"\n",
    "IMAGE_PATH= r\"C:\\Users\\varsha\\Pictures\\CV_IMG\\1200.jpg\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2d0ab98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the pre-trained model\n",
    "detect_fn = tf.saved_model.load(PATH_TO_MODEL_DIR)\n",
    "\n",
    "# Load the ImageNet labels\n",
    "with open(PATH_TO_LABELS, 'r') as f:\n",
    "    class_names = f.read().splitlines()\n",
    "\n",
    "# Perform inference on input image\n",
    "image_path = IMAGE_PATH\n",
    "image = Image.open(IMAGE_PATH)\n",
    "\n",
    "# Convert the image to a numpy array\n",
    "image_np = np.array(image)\n",
    "# print(image_np)\n",
    "# image_np = tf.io.read_file(image_path)\n",
    "# image_np = tf.image.decode_jpeg(image_np, channels=3)\n",
    "\n",
    "# Convert image data type to float32\n",
    "# image_np = tf.cast(image_np, tf.float32)\n",
    "# print((image_np/127.5).astype('int'))\n",
    "\n",
    "# Normalize pixel values to [0, 1]\n",
    "# image_np = (image_np/127.5).astype('int')\n",
    "\n",
    "# If needed, add batch dimension\n",
    "image_np = tf.expand_dims(image_np, axis=0)\n",
    "\n",
    "input_tensor = tf.convert_to_tensor(image_np)\n",
    "input_tensor = input_tensor[tf.newaxis, ...]\n",
    "\n",
    "# Perform object detection\n",
    "detections = detect_fn(image_np)\n",
    "\n",
    "# # Print detections for debugging\n",
    "# print(\"Detected Boxes:\", detections['detection_boxes'])\n",
    "# print(\"Detected Classes:\", detections['detection_classes'])\n",
    "# print(\"Detection Scores:\", detections['detection_scores'])\n",
    "\n",
    "# Extract bounding boxes, classes, and scores\n",
    "boxes = detections['detection_boxes'][0].numpy()\n",
    "classes = detections['detection_classes'][0].numpy().astype(int)\n",
    "scores = detections['detection_scores'][0].numpy()\n",
    "\n",
    "# Visualize results\n",
    "visualize_boxes(image_np[0], boxes, classes, scores, class_names)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f8249736",
   "metadata": {},
   "source": [
    "Rectangle(xy=(0.350221, 0.169153), width=0.524498, height=0.711739, angle=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf34e020",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5e1ecd6",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3548686518.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[16], line 7\u001b[1;36m\u001b[0m\n\u001b[1;33m    model = tf.\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the pre-trained model\n",
    "model = tf.keras.applications.\n",
    " \n",
    "# Load the input image\n",
    "image_path = IMAGE_PATH\n",
    "image = cv2.imread(image_path)\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Preprocess the input image\n",
    "resized_image = cv2.resize(image_rgb, (800, 800))\n",
    "normalized_image = resized_image / 255.0  # Normalize pixel values to [0, 1]\n",
    "input_image = normalized_image[tf.newaxis, ...]  # Add batch dimension\n",
    "\n",
    "# Perform inference\n",
    "detections = model.predict(input_image)\n",
    "\n",
    "# Post-process the model outputs\n",
    "boxes = detections['detection_boxes'][0].numpy()\n",
    "classes = detections['detection_classes'][0].numpy().astype(int)\n",
    "scores = detections['detection_scores'][0].numpy()\n",
    "\n",
    "# Visualize the detected objects\n",
    "for box, cls, score in zip(boxes, classes, scores):\n",
    "    if score > 0.5:  # Filter out detections with low confidence\n",
    "        ymin, xmin, ymax, xmax = box\n",
    "        xmin = int(xmin * image_rgb.shape[1])\n",
    "        xmax = int(xmax * image_rgb.shape[1])\n",
    "        ymin = int(ymin * image_rgb.shape[0])\n",
    "        ymax = int(ymax * image_rgb.shape[0])\n",
    "        cv2.rectangle(image_rgb, (xmin, ymin), (xmax, ymax), (255, 0, 0), 2)\n",
    "        cv2.putText(image_rgb, f'Class: {cls}, Score: {score:.2f}', (xmin, ymin - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "# Display the image with detected objects\n",
    "plt.imshow(image_rgb)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbe81e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ba87b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7a6d2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff69e96b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261264ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Load the pre-trained model\n",
    "# detect_fn = tf.saved_model.load(PATH_TO_MODEL_DIR)\n",
    "\n",
    "# Load the ImageNet labels\n",
    "# with open(PATH_TO_LABELS, 'r') as f:\n",
    "#     class_names = f.read().splitlines()\n",
    "\n",
    "\n",
    "# # Perform inference on input image\n",
    "# image_path = IMAGE_PATH\n",
    "# image_np = tf.io.read_file(image_path)\n",
    "\n",
    "# image_np = tf.image.decode_jpeg(image_np, channels=3)\n",
    "\n",
    "# # Convert image data type to float32\n",
    "# image_np = tf.cast(image_np, tf.float32)\n",
    "# # print(image_np)\n",
    "\n",
    "# # Normalize pixel values to [0, 1]\n",
    "# image_np /= 255.0\n",
    "# # print(image_np)\n",
    "# # # # If needed, reshape the image to match model input requirements\n",
    "# # image_np = tf.image.resize(image_np, [224, 224])  # Specify height and width\n",
    "\n",
    "# # # If needed, add batch dimension\n",
    "# image_np = tf.expand_dims(image_np, axis=0)\n",
    "\n",
    "\n",
    "# input_tensor = tf.convert_to_tensor(image_np)\n",
    "# input_tensor = input_tensor[tf.newaxis, ...]\n",
    "\n",
    "# detections = detect_fn(input_tensor)\n",
    "\n",
    "# # Extract bounding boxes, classes, and scores\n",
    "# boxes = detections['detection_boxes'][0].numpy()\n",
    "# classes = detections['detection_classes'][0].numpy().astype(int)\n",
    "# scores = detections['detection_scores'][0].numpy()\n",
    "\n",
    "# # Visualize results\n",
    "# visualize_boxes(image_np[0], boxes, classes, scores, class_names)\n",
    "\n",
    "# # # Display the results\n",
    "# # plt.imshow(image_np)\n",
    "# # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f0278a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the pre-trained model\n",
    "# detect_fn = tf.saved_model.load(PATH_TO_MODEL_DIR)\n",
    "\n",
    "# # Load the ImageNet labels\n",
    "# with open(PATH_TO_LABELS, 'r') as f:\n",
    "#     class_names = f.read().splitlines()\n",
    "\n",
    "# # Perform inference on input image\n",
    "# image_path = r\"C:\\Users\\varsha\\Pictures\\CV_IMG\\1200.jpg\"\n",
    "# image_np = tf.io.read_file(image_path)\n",
    "# image_np = tf.image.decode_jpeg(image_np, channels=3)\n",
    "\n",
    "# input_tensor = tf.convert_to_tensor(image_np)\n",
    "# input_tensor = input_tensor[tf.newaxis, ...]\n",
    "\n",
    "# detections = detect_fn(input_tensor)\n",
    "# # Print detections for debugging\n",
    "# print(\"Detected Boxes:\", detections['detection_boxes'])\n",
    "# print(\"Detected Classes:\", detections['detection_classes'])\n",
    "# print(\"Detection Scores:\", detections['detection_scores'])\n",
    "\n",
    "# # Visualize results\n",
    "# visualize_boxes(image_np, boxes, classes, scores, class_names, score_thresh=0.5)\n",
    "\n",
    "# vis_utils.visualize_boxes_and_labels_on_image_array(\n",
    "#     image_np.numpy(),\n",
    "#     detections['detection_boxes'][0].numpy(),\n",
    "#     detections['detection_classes'][0].numpy().astype(int),\n",
    "#     detections['detection_scores'][0].numpy(),\n",
    "#     class_names,\n",
    "#     use_normalized_coordinates=True,\n",
    "#     max_boxes_to_draw=200,\n",
    "#     min_score_thresh=0.5,\n",
    "#     agnostic_mode=False\n",
    "# )\n",
    "\n",
    "# # Display the results\n",
    "# plt.imshow(image_np)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c958da25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e374cc5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602509c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3182ec0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc860ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow-object-detection-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00778ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall object_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f917a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model checkpoint and pipeline configuration\n",
    "# model_checkpoint_path = PATH_TO_MODEL_DIR \n",
    "# pipeline_config_path = 'pipeline.config'\n",
    "\n",
    "# # Load label map\n",
    "# label_map_path = PATH_TO_LABELS\n",
    "# category_index = load_label_map(PATH_TO_LABELS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01488f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11a6236",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc843e72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09129c6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fea358",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9c52f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803518f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964059cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88062704",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
