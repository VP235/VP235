{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "53f004e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from keras import Sequential\n",
    "from keras.optimizers.legacy import Adam\n",
    "from keras.layers import Dense, LeakyReLU, BatchNormalization\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2b86cd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input image dimension\n",
    "img_rows= 28\n",
    "img_col= 28\n",
    "imh_channel= 1\n",
    "\n",
    "img_shape= (img_rows, img_col, imh_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "07ff4587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise/ latent vector -> it is nothing but the randomly generated 1D array of size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb88032",
   "metadata": {},
   "source": [
    "### Generator:\n",
    "\n",
    "#### Given input image as noise or vector latent produces the generator produces fake image\n",
    "\n",
    "#### for our model, it takes in 1D randomly generated noise and returns back a image by converting it into into (28,28,1) shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c651291c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def  build_generator():\n",
    "    \n",
    "    noise_shape= (100, ) # 1D array of size 100 that will be passed to the generator\n",
    "    \n",
    "    # for now we will be using only the simple neural network but the networks can be complicated, depends on the purpose\n",
    "    # Created a Sequential model\n",
    "    model= Sequential()\n",
    "    \n",
    "    model.add(Dense(256, input_shape= noise_shape))  # this input_shape is defined for the Sequential model's first layer (which we usually do, to pass input)\n",
    "    model.add(keras.layers.LeakyReLU(alpha= 0.2))     #dont know why alpha is 0.2, taken directly from the research paper\n",
    "    model.add(keras.layers.BatchNormalization(momentum= 0.8)) # momentum specifices at what rate or how fast to the model should be train\n",
    "    \n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    \n",
    "    model.add(Dense(1024))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    \n",
    "    model.add(Dense(np.prod(img_shape), activation= 'tanh')) # it like applying activation on (z)= weights+bias -> tanh(z)\n",
    "    model.add(keras.layers.Reshape(img_shape))  # Layer that reshapes inputs into the given shape.\n",
    "    \n",
    "    print('----------------------Build Generator - Sequential Layers--------------------------------')\n",
    "    model.summary()\n",
    "    \n",
    "    # cerate a Functional API Model , beecause it is more flexible for non-linear problems like GAN and is more flexible.\n",
    "    noise= keras.layers.Input(shape= noise_shape)  #`For Functional API model, we need to define the input layer \n",
    "    generated_img= model(noise)      # Generated image : whatever the image is generated from the Sequential model as output it to the Functional API model\n",
    "    \n",
    "#     print('----------------------Build Generator - Wrap Sequential Layers in Functional API--------------------------------')\n",
    "    functioalApi_model= keras.models.Model(noise, generated_img)\n",
    "    functioalApi_model.summary()\n",
    "    \n",
    "    \n",
    "    return functioalApi_model# defining a functional API model\n",
    "#Alpha — α is a hyperparameter It allows a small gradient when the unit is not active. It takes activation to near zero, instead of complete zero.\n",
    "#Momentum — Speed up the training\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "cdd705fd",
   "metadata": {},
   "source": [
    "# Leaky Relu :It allows a small gradient when the unit is not active\n",
    "\n",
    "# Batch normalization :Applies a transformation that maintains the mean output close to 0 and the output standard deviation                        close to 1.\n",
    "\n",
    "Importantly, batch normalization works differently during training and during inference:\n",
    "\n",
    "1] During training (i.e. when using fit() or when calling the layer/model with the argument training=True), the layer normalizes its output using the mean and standard deviation of the current batch of inputs. \n",
    "\n",
    "2] During inference (i.e. when using evaluate() or predict() or when calling the layer/model with the argument training=False (which is the default), the layer normalizes its output using a moving average of the mean and standard deviation of the batches it has seen during training. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc11f20",
   "metadata": {},
   "source": [
    "### Descriminator:\n",
    "\n",
    "\n",
    "#### Given an input image, the Discriminator outputs the likelihood of the image being real.\n",
    "#### Binary classification - true or false (we're calling it validity)\n",
    "\n",
    "#### First we flatten the image of size(28,28,1 ) to a 1D array to passin to the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "8afafbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    \n",
    "    model= Sequential()\n",
    "    \n",
    "    model.add(keras.layers.Flatten(input_shape= img_shape))\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(256))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    print('----------------------Build Discriminator--------------------------------')\n",
    "    model.summary()\n",
    "    \n",
    "    img= keras.layers.Input(shape= img_shape)\n",
    "    validity= model(img)                      #The validity is the Discriminator’s guess of input being real or not.\n",
    "    \n",
    "#     print('----------------------Build Generator - Wrap Sequential Layers in Functional API--------------------------------')\n",
    "    functioalApi_model= keras.models.Model(img, validity)\n",
    "    functioalApi_model.summary()\n",
    "    \n",
    "    return functioalApi_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ba048493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training function\n",
    "\n",
    "def train( epochs, batch_size=128 , save_interval= 50):\n",
    "    \n",
    "    # load the dataset\n",
    "    (X_train, _),(_, _)= keras.datasets.mnist.load_data()\n",
    "    \n",
    "    # convert it to float from uint8 and normalize the data between -1 to 1 (we can also scale it to 0 to -1)\n",
    "    X_train= (X_train.astype('float32')-127.5)/127.5\n",
    "    \n",
    "    # we will add a dimension of channel =1, as the input to our generator and desc is img of size (28,28,1)\n",
    "    X_train= np.expand_dims(X_train, axis= 3)\n",
    "    \n",
    "    # now will divide the batch size to half, so that we can give half of the batch to training purpose \n",
    "    half_batch= int(batch_size/2)\n",
    "    \n",
    "    \n",
    "    #We then loop through a number of epochs to train our Discriminator by first selecting\n",
    "    #a random batch of images from our true dataset, generating a set of images from our\n",
    "    #Generator, feeding both set of images into our Discriminator, and finally setting the\n",
    "    #loss parameters for both the real and fake images, as well as the combined loss. \n",
    "\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "       # train the discriminator\n",
    "        \n",
    "        #selectthe random half batch of real images \n",
    "        idx= np.random.randint(0, X_train.shape[0], half_batch)\n",
    "        imgs = X_train[idx]\n",
    "        \n",
    "        # create a noise for descriminator training\n",
    "        noise= np.random.normal(0, 1, (half_batch, 100))  # Draw random samples from a normal (Gaussian) distribution.\n",
    "        \n",
    "        # generate half batch of fake image\n",
    "        gen_img= generator.predict(noise)\n",
    "        \n",
    "        \n",
    "        # Train the discriminator on real and fake images, separately\n",
    "        #Research showed that separate training is more effective. \n",
    "        d_loss_real= discriminator.train_on_batch(imgs, np.ones((half_batch,1)))   # Runs a single gradient update on a single batch of data, it returns scalar training loss\n",
    "        d_loss_fake= discriminator.train_on_batch(gen_img, np.zeros((half_batch,1)))\n",
    "        \n",
    "        \n",
    "        # take avg loss for real and fake\n",
    "        d_loss= 0.5* np.add(d_loss_real,d_loss_fake)\n",
    "        \n",
    "        #And within the same loop we train our Generator, by setting the input noise and\n",
    "        #ultimately training the Generator to have the Discriminator label its samples as valid\n",
    "        #by specifying the gradient loss.\n",
    "        \n",
    "        # Note: When we train the descriminator, at that time we keep the generator non trainable\n",
    "                # and when we train the generator, descriminator is kept non-trainable\n",
    "                # we do it so that generator do not adjust the weights in descriminator\n",
    "                \n",
    "                \n",
    "        # -------------------Train Generator----------------------\n",
    "        \n",
    "        #Create noise vectors as input for generator training.\n",
    "        #Create as many noise vectors as defined by the batch size. \n",
    "        #Based on normal distribution. Output will be of size (batch size, 100)\n",
    "        \n",
    "        noise= np.random.normal( 0, 1, (batch_size, 100))\n",
    "        \n",
    "        # The generator wants the discriminator to label the generated samples\n",
    "        # as valid (ones)\n",
    "        #This is where the genrator is trying to trick discriminator into believing\n",
    "        #the generated image is true (hence value of 1 for y)\n",
    "        valid_y = np.array([1] * batch_size) #Creates an array of all ones of size=batch size\n",
    "\n",
    "        \n",
    "        # Generator is part of combined where it got directly linked with the discriminator\n",
    "        # Train the generator with noise as x and 1 as y. \n",
    "        # Again, 1 as the output as it is adversarial and if generator did a great\n",
    "        #job of folling the discriminator then the output would be 1 (true)\n",
    "\n",
    "        g_loss= combined.train_on_batch(noise, valid_y)\n",
    "        \n",
    "        #Additionally, in order for us to keep track of our training process, we print the\n",
    "        #progress and save the sample image output depending on the epoch interval specified.  \n",
    "        # Plot the progress\n",
    "        \n",
    "        print (f\"{epochs} [D loss: {d_loss[0]}, acc.: {np.round(100*d_loss[1],2)}] [G loss: {g_loss}]\")\n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "acf7b624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------Build Discriminator--------------------------------\n",
      "Model: \"sequential_77\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_9 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_111 (Dense)           (None, 512)               401920    \n",
      "                                                                 \n",
      " leaky_re_lu_81 (LeakyReLU)  (None, 512)               0         \n",
      "                                                                 \n",
      " dense_112 (Dense)           (None, 256)               131328    \n",
      "                                                                 \n",
      " leaky_re_lu_82 (LeakyReLU)  (None, 256)               0         \n",
      "                                                                 \n",
      " dense_113 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 533505 (2.04 MB)\n",
      "Trainable params: 533505 (2.04 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"model_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_38 (InputLayer)       [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " sequential_77 (Sequential)  (None, 1)                 533505    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 533505 (2.04 MB)\n",
      "Trainable params: 533505 (2.04 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "----------------------After Building Discriminator--------------------------------\n",
      "Model: \"model_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_38 (InputLayer)       [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " sequential_77 (Sequential)  (None, 1)                 533505    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 533505 (2.04 MB)\n",
      "Trainable params: 533505 (2.04 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "----------------------Build Generator - Sequential Layers--------------------------------\n",
      "Model: \"sequential_78\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_114 (Dense)           (None, 256)               25856     \n",
      "                                                                 \n",
      " leaky_re_lu_83 (LeakyReLU)  (None, 256)               0         \n",
      "                                                                 \n",
      " batch_normalization_63 (Ba  (None, 256)               1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_115 (Dense)           (None, 512)               131584    \n",
      "                                                                 \n",
      " leaky_re_lu_84 (LeakyReLU)  (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_64 (Ba  (None, 512)               2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_116 (Dense)           (None, 1024)              525312    \n",
      "                                                                 \n",
      " leaky_re_lu_85 (LeakyReLU)  (None, 1024)              0         \n",
      "                                                                 \n",
      " batch_normalization_65 (Ba  (None, 1024)              4096      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_117 (Dense)           (None, 784)               803600    \n",
      "                                                                 \n",
      " reshape_22 (Reshape)        (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1493520 (5.70 MB)\n",
      "Trainable params: 1489936 (5.68 MB)\n",
      "Non-trainable params: 3584 (14.00 KB)\n",
      "_________________________________________________________________\n",
      "Model: \"model_34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_39 (InputLayer)       [(None, 100)]             0         \n",
      "                                                                 \n",
      " sequential_78 (Sequential)  (None, 28, 28, 1)         1493520   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1493520 (5.70 MB)\n",
      "Trainable params: 1489936 (5.68 MB)\n",
      "Non-trainable params: 3584 (14.00 KB)\n",
      "_________________________________________________________________\n",
      "----------------------After Building Generator--------------------------------\n",
      "Model: \"model_34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_39 (InputLayer)       [(None, 100)]             0         \n",
      "                                                                 \n",
      " sequential_78 (Sequential)  (None, 28, 28, 1)         1493520   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1493520 (5.70 MB)\n",
      "Trainable params: 1489936 (5.68 MB)\n",
      "Non-trainable params: 3584 (14.00 KB)\n",
      "_________________________________________________________________\n",
      "----------------------Combined Generator and Discriminator--------------------------------\n",
      "Model: \"model_35\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_40 (InputLayer)       [(None, 100)]             0         \n",
      "                                                                 \n",
      " model_34 (Functional)       (None, 28, 28, 1)         1493520   \n",
      "                                                                 \n",
      " model_33 (Functional)       (None, 1)                 533505    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2027025 (7.73 MB)\n",
      "Trainable params: 1489936 (5.68 MB)\n",
      "Non-trainable params: 537089 (2.05 MB)\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "1 [D loss: 0.9239471554756165, acc.: 43.75] [G loss: 0.8967821002006531]\n"
     ]
    }
   ],
   "source": [
    "#######################################################################\n",
    "    \n",
    "# define a optimzer for easy access\n",
    "optimizer= Adam(0.0002, 0.5)  #Learning rate and momentum.\n",
    "\n",
    "# Build and compile the discriminator first. \n",
    "#Generator will be trained as part of the combined model, later. \n",
    "#pick the loss function and the type of metric to keep track.                 \n",
    "#Binary cross entropy as we are doing prediction and it is a better loss function compared to MSE or other \n",
    "#for binary(0 or 1) output\n",
    "\n",
    "discriminator= build_discriminator()\n",
    "discriminator.compile(optimizer= optimizer,\n",
    "                     loss= 'binary_crossentropy',\n",
    "                     metrics= ['accuracy'])\n",
    "\n",
    "print('----------------------After Building Discriminator--------------------------------')\n",
    "discriminator.summary()\n",
    "#build and compile our Discriminator, pick the loss function\n",
    "\n",
    "#since we are only generating (faking) images, let us not track any metrics.\n",
    "generator= build_generator()\n",
    "generator.compile(optimizer= optimizer,\n",
    "                loss= 'binary_crossentropy')\n",
    "\n",
    "print('----------------------After Building Generator--------------------------------')\n",
    "generator.summary()\n",
    "\n",
    "#This builds the Generator and defines the input noise. \n",
    "#In a GAN the Generator network takes noise z as an input to produce its images.  \n",
    "z= keras.layers.Input(shape= (100,))\n",
    "img= generator(z)\n",
    "\n",
    "# plt.imshow(img[0])\n",
    "#This ensures that when we combine our networks we only train the Generator.\n",
    "#While generator training we do not want discriminator weights to be adjusted. \n",
    "#This Doesn't affect the above descriminator training.\n",
    "\n",
    "discriminator.trainable= False\n",
    "\n",
    "#This specifies that our Discriminator will take the images generated by our Generator\n",
    "#and true dataset and set its output to a parameter called valid, which will indicate\n",
    "#whether the input is real or not.  \n",
    "\n",
    "valid= discriminator(img)   #Validity check on the generated image\n",
    "\n",
    "\n",
    "\n",
    "#Here we combined the models and also set our loss function and optimizer. \n",
    "#Again, we are only training the generator here. \n",
    "#The ultimate goal here is for the Generator to fool the Discriminator.  \n",
    "# The combined model  (stacked generator and discriminator) takes\n",
    "# noise as input => generates images => determines validity\n",
    "\n",
    "combined= keras.models.Model(z, valid) \n",
    "\n",
    "print('----------------------Combined Generator and Discriminator--------------------------------')\n",
    "combined.summary()\n",
    "combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "\n",
    "train(epochs= 1, batch_size=32, save_interval=10)\n",
    "\n",
    "#Save model for future use to generate fake images\n",
    "#Not tested yet... make sure right model is being saved..\n",
    "#Compare with GAN4\n",
    "\n",
    "# generator.save('generator_model.h5')  #Test the model on GAN4_predict...\n",
    "#Change epochs back to 30K\n",
    "                \n",
    "#Epochs dictate the number of backward and forward propagations, the batch_size\n",
    "#indicates the number of training samples per backward/forward propagation, and the\n",
    "#sample_interval specifies after how many epochs we call our sample_image function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "84562d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = keras.layers.Input(shape=(32,))\n",
    "# y = tf.square(x)  # This op will be treated like a layer\n",
    "# model = keras.models.Model(x, y)\n",
    "# model.summary()\n",
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f1ee17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c890d28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 18ms/step\n"
     ]
    }
   ],
   "source": [
    " noise_shape= (100, ) # 1D array of size 100 that will be passed to the generator\n",
    "    \n",
    "# for now we will be using only the simple neural network but the networks can be complicated, depends on the purpose\n",
    "\n",
    "model= Sequential()\n",
    "model.add(Dense(256, input_shape= noise_shape))\n",
    "model.add(keras.layers.LeakyReLU(alpha= 0.2))     #dont know why alpha is 0.2, taken directly from the research paper\n",
    "model.add(keras.layers.BatchNormalization(momentum= 0.8)) # momentum specifices at what rate or how fast to the model should be train\n",
    "model.add(Dense(512))\n",
    "model.add(LeakyReLU(alpha=0.2))\n",
    "model.add(BatchNormalization(momentum=0.8))\n",
    "model.add(Dense(1024))\n",
    "model.add(LeakyReLU(alpha=0.2))\n",
    "model.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "model.add(Dense(np.prod(img_shape), activation= 'tanh')) # it like applying activation on (z)= weights+bias -> tanh(z)\n",
    "model.add(keras.layers.Reshape(img_shape))  # Layer that reshapes inputs into the given shape.\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "# noise= keras.layers.Input(shape= noise_shape)  #`Input()` is used to instantiate a Keras tensor.\n",
    "# generated_img= model(noise)      # Generated image\n",
    "#           # Generated image\n",
    "# print(noise)\n",
    "# print(\"===========generated------------\",generated_img)\n",
    "# chit= keras.models.Model(noise, generated_img)\n",
    "# print(\"---------------------hi\", chit)\n",
    "noise= np.random.normal(0, 1, (64, 100))\n",
    "img= model.predict(noise)\n",
    "\n",
    "# keras.utils.plot_model(chit, \"model.png\",show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9b7c9f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c2404da650>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "94cdd61a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones((1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "ee35b429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 106ms/step\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(10, 50, embeddings_initializer=\"ones\")) #Try \"uniform\" and \"ones\" initializer\n",
    "\n",
    "#Array of size 10, --> should output size (10,1,50)\n",
    "input_array = np.array([5])\n",
    "output_array = model.predict(input_array)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "10e90082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "589562cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 1, 50) dtype=float32 (created by layer 'embedding_47')>"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deca8518",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769b8013",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7991ce99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8344ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd7ca3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1904eeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e552dd3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
