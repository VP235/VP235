{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "29f0b9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Layer,Input,Concatenate, Conv2D, Embedding, MaxPool2D, Flatten, Dropout, Dense, LeakyReLU, BatchNormalization, Reshape, Conv2DTranspose\n",
    "from keras.models import Model\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "682d97fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(in_shape=(32,32,3), n_labels= 10):      # cifair image shape is 32x32x3\n",
    "    \n",
    "    \n",
    "    # initialize the input layer\n",
    "    input_layer= Input(shape= (1,))   \n",
    "    \n",
    "    # embedding for categorical input each label (total 10 classes for cifar), will be represented by a vector \n",
    "    # of size 50. This vector of size 50 will be learnt by the discriminator\n",
    "    in_labels= Embedding(n_labels, 50)(input_layer) #Shape 1,50 scale up to image dimensions with linear activatio\n",
    "    \n",
    "    n_nodes= in_shape[0] * in_shape[1]    #32x32 = 1024.\n",
    "    \n",
    "    layer_2= Dense(n_nodes)(in_labels)\n",
    "    layer_3= Reshape((in_shape[0],in_shape[1],1))(layer_2)\n",
    "    \n",
    "    in_image= Input(shape= in_shape)\n",
    "    merge= Concatenate()([in_image, layer_3])  # n, 32, 32, 4 \n",
    "    \n",
    "      \n",
    "    layer_4= Conv2D(128, (4,4), (2,2), padding= 'same')(merge)    # 16 X 16 x128\n",
    "    layer_4= LeakyReLU(alpha= 0.2)(layer_4)\n",
    "    \n",
    "    layer_5= Conv2D(128, (4,4), (2,2), padding= 'same')(layer_4)  # 8x8x128\n",
    "    layer_5= LeakyReLU(alpha= 0.2)(layer_5)\n",
    "\n",
    "    layer_6= Flatten()(layer_5)              #8192  (8*8*128=8192)\n",
    "    out_layer= Dense(1, activation= 'sigmoid')(layer_6)    # shape= 1\n",
    "    \n",
    "    \n",
    "    model= Model([in_image, in_labels], out_layer)\n",
    "    \n",
    "    model.compile(optimizer='Adam',\n",
    "                 loss= 'binary_crossentropy',\n",
    "                 metrics= ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f1f6afbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_32 (InputLayer)       [(None, 1, 50)]              0         []                            \n",
      "                                                                                                  \n",
      " dense_19 (Dense)            (None, 1, 1024)              52224     ['input_32[0][0]']            \n",
      "                                                                                                  \n",
      " input_31 (InputLayer)       [(None, 32, 32, 3)]          0         []                            \n",
      "                                                                                                  \n",
      " reshape_13 (Reshape)        (None, 32, 32, 1)            0         ['dense_19[1][0]']            \n",
      "                                                                                                  \n",
      " concatenate_10 (Concatenat  (None, 32, 32, 4)            0         ['input_31[0][0]',            \n",
      " e)                                                                  'reshape_13[1][0]']          \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)          (None, 16, 16, 128)          8320      ['concatenate_10[1][0]']      \n",
      "                                                                                                  \n",
      " leaky_re_lu_10 (LeakyReLU)  (None, 16, 16, 128)          0         ['conv2d_10[1][0]']           \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)          (None, 8, 8, 128)            262272    ['leaky_re_lu_10[1][0]']      \n",
      "                                                                                                  \n",
      " leaky_re_lu_11 (LeakyReLU)  (None, 8, 8, 128)            0         ['conv2d_11[1][0]']           \n",
      "                                                                                                  \n",
      " flatten_5 (Flatten)         (None, 8192)                 0         ['leaky_re_lu_11[1][0]']      \n",
      "                                                                                                  \n",
      " dense_20 (Dense)            (None, 1)                    8193      ['flatten_5[1][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 331009 (1.26 MB)\n",
      "Trainable params: 331009 (1.26 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "test_discr = build_discriminator()\n",
    "print(test_discr.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "18c8db79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(latent_dim, n_labels= 10):\n",
    "    \n",
    "        inp_labels= Input((1,))\n",
    "        layer_1= Embedding(n_labels, 50)(inp_labels)\n",
    "        \n",
    "        n_nodes= 8*8                                 # To match the dimensions for concatenation later in this step. \n",
    "        \n",
    "        layer_2= Dense(n_nodes)(layer_1)\n",
    "        layer_3= Reshape((8,8,1))(layer_2)           # reshape so that we can add with the dense layer of size 8 x 8x 128\n",
    "    \n",
    "        inp_layer= Input((latent_dim,))              #Input of dimension 100\n",
    "        \n",
    "        n_nodes= 8*8*128                             #shape=8192\n",
    "        \n",
    "        li= Dense(n_nodes)(inp_layer)\n",
    "        li = LeakyReLU(alpha=0.2)(li)\n",
    "        li= Reshape((8, 8, 128))(li)                   # 8 x 8 x 128\n",
    "        \n",
    "        merge= Concatenate()([li, layer_3])         #Shape=8x8x129 (Extra channel corresponds to the label)\n",
    "        \n",
    "        layer_5= Conv2DTranspose(128, (4,4), (2,2), padding= 'same')(merge)   # 16 x 16 x128\n",
    "        layer_5= LeakyReLU(alpha=(0.2))(layer_5)\n",
    "        \n",
    "        layer_6= Conv2DTranspose(128, (4,4), (2,2), padding= 'same')(layer_5)   # 32 X 32 X 128\n",
    "        layer_6= LeakyReLU(alpha= 0.2)(layer_6)\n",
    "        \n",
    "        out_layer= Conv2D(3, (8, 8), activation= 'tanh', padding= 'same')(layer_6)  # 32 x 32 x 3\n",
    "        \n",
    "        model= Model([inp_layer, inp_labels], out_layer)\n",
    "        \n",
    "        return model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c290c00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_36 (InputLayer)       [(None, 100)]                0         []                            \n",
      "                                                                                                  \n",
      " input_35 (InputLayer)       [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " dense_24 (Dense)            (None, 8192)                 827392    ['input_36[0][0]']            \n",
      "                                                                                                  \n",
      " embedding_16 (Embedding)    (None, 1, 50)                500       ['input_35[0][0]']            \n",
      "                                                                                                  \n",
      " leaky_re_lu_15 (LeakyReLU)  (None, 8192)                 0         ['dense_24[0][0]']            \n",
      "                                                                                                  \n",
      " dense_23 (Dense)            (None, 1, 64)                3264      ['embedding_16[0][0]']        \n",
      "                                                                                                  \n",
      " reshape_17 (Reshape)        (None, 8, 8, 128)            0         ['leaky_re_lu_15[0][0]']      \n",
      "                                                                                                  \n",
      " reshape_16 (Reshape)        (None, 8, 8, 1)              0         ['dense_23[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate_12 (Concatenat  (None, 8, 8, 129)            0         ['reshape_17[0][0]',          \n",
      " e)                                                                  'reshape_16[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2D  (None, 16, 16, 128)          264320    ['concatenate_12[0][0]']      \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " leaky_re_lu_16 (LeakyReLU)  (None, 16, 16, 128)          0         ['conv2d_transpose_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2D  (None, 32, 32, 128)          262272    ['leaky_re_lu_16[0][0]']      \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " leaky_re_lu_17 (LeakyReLU)  (None, 32, 32, 128)          0         ['conv2d_transpose_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)          (None, 32, 32, 3)            24579     ['leaky_re_lu_17[0][0]']      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1382327 (5.27 MB)\n",
      "Trainable params: 1382327 (5.27 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "test_gen = build_generator(100, n_labels=10)\n",
    "print(test_gen.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3e12d07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gan(g_model, d_model, latent_dim):\n",
    "    \n",
    "    # do not train discriminator when traininf generator\n",
    "    d_model.trainiable= False\n",
    "    \n",
    "    ## connect generator and discriminator...\n",
    "    # first, get noise and label inputs from generator model\n",
    "    gen_noise, gen_label= g_model.input()\n",
    "    \n",
    "    # get image output from the generator model\n",
    "    gen_output= g_model.output()              # 32x32x3\n",
    "    \n",
    "    # generator image output and corresponding input label are inputs to discriminator\n",
    "    dec_output= d_model(gen_output, gen_label)\n",
    "    \n",
    "    # define gan model as taking noise and label and outputting a classification\n",
    "    model= Model([gen_noise, gen_label], dec_output)\n",
    "    \n",
    "    # compile the model\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(optimizer= opt, \n",
    "                 loss= 'binary_crossentropy')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1d65e952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load real images \n",
    "\n",
    "def load_real_samples():\n",
    "    \n",
    "    (X_train, y_train),(_, _)= keras.datasets.cifar10.load_data()\n",
    "    \n",
    "    # convert the images into float\n",
    "    X_train = X_train.astype('float32')\n",
    "    \n",
    "    # Normalize the images\n",
    "    X_train= (X_train-127.5)/127.5\n",
    "    \n",
    "    \n",
    "    return [X_train, y_train]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "89d6271d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_samples(dataset, n_samples):\n",
    "    \n",
    "    # split into images and labels\n",
    "    \n",
    "    images, labels= dataset\n",
    "    \n",
    "    \n",
    "    # choose random instances\n",
    "    idx= np.random.randint(0, images.shape[0], n_samples)\n",
    "    \n",
    "    # select images and labels\n",
    "    real_img, labels= images[idx], labels[idx]\n",
    "    \n",
    "    # generate class labels and assign to y (don't confuse this with the above labels that correspond to cifar labels)\n",
    "    y_ones= np.ones((n_samples, 1))\n",
    "    \n",
    "    return [real_img, labels], y_ones\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "74ff4ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate  latent point\n",
    "\n",
    "def generate_latent_point(latent_point, n_samples, n_classes= 10):\n",
    "    \n",
    "    # generate points in the latent space\n",
    "    noise= np.random.normal(0, 1, (n_samples, latent_point))\n",
    "    \n",
    "    # generate the labels\n",
    "    labels= randint(0, n_classes, n_samples)\n",
    "    \n",
    "    return [noise, labels]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f44edd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate fake images\n",
    "\n",
    "def generate_fake_images(latent_point, n_sample, generator):\n",
    "    \n",
    "    # generate latent points and labels\n",
    "    latent_point, labels= generate_latent_point(latent_point, n_sample)\n",
    "    \n",
    "    # generate fake images\n",
    "    fake_imgs= generator.predict([latent_point, labels])\n",
    "    \n",
    "    # create class labels\n",
    "    y= np.zeros((n_sample, 1))\n",
    "    \n",
    "    return [fake_imgs, labels], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "32917d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the generator and discriminator\n",
    "#We loop through a number of epochs to train our Discriminator by first selecting\n",
    "#a random batch of images from our true/real dataset.\n",
    "#Then, generating a set of images using the generator. \n",
    "#Feed both set of images into the Discriminator. \n",
    "#Finally, set the loss parameters for both the real and fake images, as well as the combined loss. \n",
    "\n",
    "def train(epochs, batch_size, g_model, d_model, gan_model, dataset, latent_point):\n",
    "    \n",
    "    batch_per_epoch= dataset.shape[0]/batch_size\n",
    "    half_batch= int(batch_size/2)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for batch in range(batch_per_epoch):\n",
    "            \n",
    "            \n",
    "            # generate real images\n",
    "            [X_real, labels_real], y_real= generate_real_samples(dataset, half_batch)\n",
    "            \n",
    "            # train discriminator on the real images\n",
    "            d_loss_real= d_model.train_on_batch([X_real, labels_real], y_real)\n",
    "            \n",
    "            # generate fake images\n",
    "            [X_fake, labels_fake], y_fake= generate_fake_images(latent_point, half_batch, g_model)\n",
    "            \n",
    "            d_loss_fake= d_model.train_on_batch([X_fake, labels_fake], y_fake)\n",
    "            \n",
    "            # prepare points in latent space as input for the generator\n",
    "            [z_input, label_input]= generate_latent_point(latent_point, half_batch)\n",
    "            \n",
    "            #The generator wants the discriminator to label the generated samples as valid (ones)\n",
    "            #This is where the generator is trying to trick discriminator into believing\n",
    "            #the generated image is true (hence value of 1 for y) create inverted labels for the fake samples\n",
    "            \n",
    "            y_fake= np.ones((batch_size,1))\n",
    "            \n",
    "            \n",
    "            # Generator is part of combined model where it got directly linked with the discriminator\n",
    "            # Train the generator with latent_dim as x and 1 as y. \n",
    "            # Again, 1 as the output as it is adversarial and if generator did a great\n",
    "            #job of folling the discriminator then the output would be 1 (true)\n",
    "            \n",
    "            # update the generator via the discriminator's error\n",
    "            \n",
    "            valid= gan_model.train_on_batch([z_input, label_input], y_fake)\n",
    "            \n",
    "            \n",
    "            # Print losses on this batch\n",
    "            print('Epoch>%d, Batch%d/%d, d1=%.3f, d2=%.3f g=%.3f' % (i+1, j+1, batch_per_epoch, d_loss_real, d_loss_fake, g_loss))\n",
    "           \n",
    "            # save the generator model\n",
    "            g_model.save('cifar_conditional_generator_25epochs.h5')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033a896f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the gan\n",
    "\n",
    "# size of latent\n",
    "latent_dim= 100\n",
    "\n",
    "# create the driscriminator\n",
    "d_model= build_discriminator()\n",
    "\n",
    "# create generator\n",
    "g_model= build_generator()\n",
    "\n",
    "# create gan\n",
    "gan_model = generate_gan(g_model, d_model, latent_dim)\n",
    "\n",
    "\n",
    "# load images\n",
    "dataset= load_real_samples()\n",
    "\n",
    "# train model\n",
    "train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb8ec97",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "# Now, let us load the generator model and generate images\n",
    "# Lod the trained model and generate a few images\n",
    "from numpy import asarray\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "# \n",
    "\n",
    "#Note: CIFAR10 classes are: airplane, automobile, bird, cat, deer, dog, frog, horse,\n",
    "# ship, truck\n",
    "\n",
    "# load model\n",
    "model = load_model('cifar_conditional_generator_250epochs.h5')\n",
    "\n",
    "# generate multiple images\n",
    "\n",
    "latent_points, labels = generate_latent_points(100, 100)\n",
    "# specify labels - generate 10 sets of labels each gping from 0 to 9\n",
    "labels = asarray([x for _ in range(10) for x in range(10)])\n",
    "# generate images\n",
    "X  = model.predict([latent_points, labels])\n",
    "# scale from [-1,1] to [0,1]\n",
    "X = (X + 1) / 2.0\n",
    "X = (X*255).astype(np.uint8)\n",
    "# plot the result (10 sets of images, all images in a column should be of same class in the plot)\n",
    "# Plot generated images \n",
    "def show_plot(examples, n):\n",
    "\tfor i in range(n * n):\n",
    "\t\tplt.subplot(n, n, 1 + i)\n",
    "\t\tplt.axis('off')\n",
    "\t\tplt.imshow(examples[i, :, :, :])\n",
    "\tplt.show()\n",
    "    \n",
    "show_plot(X, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a93cea4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c658b1c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0866a0e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1c0e75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f438940f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
