{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06bce7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305e84d1",
   "metadata": {},
   "source": [
    "#### Pipeline Steps:\n",
    "\n",
    "    Getting access to the webcam.\n",
    "    Setup mouse event.\n",
    "    Initialize the tracker.\n",
    "    Track an object in real-time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cced86e3",
   "metadata": {},
   "source": [
    "### Step-1 : Getting access to the webcamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb27f906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a name for the window\n",
    "windowName= 'Output Window'\n",
    "cv2.namedWindow(windowName)\n",
    "\n",
    "#Initialize a captureVideo object\n",
    "cap= cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    \n",
    "    #reads each frame from the webcam\n",
    "    ret, frame= cap.read()\n",
    "    output= frame\n",
    "    \n",
    "    #show frame in new window\n",
    "    cv2.imshow(windowName, output)\n",
    "    \n",
    "    #waits 1 ms between each frame and continues to show the frames untill pressed 'q'\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "#release the capture object\n",
    "cap.release()\n",
    "\n",
    "#close all active windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c775baa",
   "metadata": {},
   "source": [
    "## Step 2: Mouse Event\n",
    "\n",
    "Why are we using mouse events in this project?\n",
    "\n",
    "Here, we don’t want our tracker to track only one specific object at each program run. But we want to select in real-time to track an object and can also change the track focus to another object without closing the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "299de4d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window_w32.cpp:2543: error: (-27:Null pointer) NULL window: 'Output Window' in function 'cvSetMouseCallback'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 40\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m event\u001b[38;5;241m==\u001b[39m cv2\u001b[38;5;241m.\u001b[39mEVENT_RBUTTONDOWN:\n\u001b[0;32m     38\u001b[0m         can_track\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m cv2\u001b[38;5;241m.\u001b[39msetMouseCallback(windowName, click_event)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window_w32.cpp:2543: error: (-27:Null pointer) NULL window: 'Output Window' in function 'cvSetMouseCallback'\n"
     ]
    }
   ],
   "source": [
    "x, y, w, h= 0, 0, 0, 0\n",
    "first_point_saved= False\n",
    "second_point_saved= False\n",
    "track_window= (x, y, h, w)\n",
    "can_track= False\n",
    "\n",
    "# this function returns the coordinate points of the opencv window where the event happens\n",
    "def click_event(event, px, py):\n",
    "    global x, y, w, h, first_point_saved, second_point_saved, track_window, can_track\n",
    "    \n",
    "    # left mouse button released\n",
    "    if event== cv2.EVENT_LBUTTONUP:\n",
    "        \n",
    "        print(cv2.EVENT_LBUTTONUP)\n",
    "        \n",
    "        #if true means first point is saved then we calculate the tracker window height and width.\n",
    "        if first_point_saved:\n",
    "            \n",
    "            w= px-x\n",
    "            h= py-y\n",
    "            \n",
    "            track_window= (x, y, w, h)\n",
    "            print(x, y, w, h)\n",
    "            \n",
    "            first_point_saved= False\n",
    "            second_point_saved= True\n",
    "            \n",
    "            \n",
    "        else: \n",
    "            x= px\n",
    "            y= py\n",
    "            \n",
    "            first_point_saved= True\n",
    "            can_track= False\n",
    "        \n",
    "    # this will stop the tracker from tracking\n",
    "    if event== cv2.EVENT_RBUTTONDOWN:\n",
    "        can_track= False\n",
    "\n",
    "cv2.setMouseCallback(windowName, click_event)       #start event mouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad9217b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "6 5 0 0\n"
     ]
    }
   ],
   "source": [
    "click_event( cv2.EVENT_LBUTTONUP, 6, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d291ad7",
   "metadata": {},
   "source": [
    "###  Step 3: Initialize the Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a282f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize tracker\n",
    "def initializeTracker(frame, track_window):\n",
    "    x, y, w, h= track_window\n",
    "    \n",
    "    # Camshift is a colorbased tracker so we first set up the ROI. \n",
    "    # ROI is basically the cropped image of the selcted object's window.\n",
    "    \n",
    "    roi= frame[y:y+h, x:x+w]\n",
    "    \n",
    "    hsv_roi= cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Calculate the histogram of the colors\n",
    "    roi_hist= cv2.calcHist([hsv_roi],[0], None, [180], [0,180])\n",
    "    \n",
    "    # filters some noises in the histogram.\n",
    "    roi_hist= cv2.normalize(roi_hist, roi_hist, 0, 255, cv2.NORM_MINMAX)\n",
    "    \n",
    "    return roi_hist, roi\n",
    "\n",
    "# value for the criteria 10 and 1 means the tracker updates either every 10 iterations or moves by at least 1 point.\n",
    "term_crit= (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faab4df6",
   "metadata": {},
   "source": [
    "### Step 4: Track an object in real time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "91ad4d8a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m hsv\u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2HSV)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m second_point_saved:\n\u001b[1;32m----> 7\u001b[0m     roi_hist, roi\u001b[38;5;241m=\u001b[39m initializeTracker(frame, windowName)\n\u001b[0;32m      8\u001b[0m     second_point_saved\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     can_track\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[23], line 3\u001b[0m, in \u001b[0;36minitializeTracker\u001b[1;34m(frame, track_window)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minitializeTracker\u001b[39m(frame, track_window):\n\u001b[1;32m----> 3\u001b[0m     x, y, w, h\u001b[38;5;241m=\u001b[39m track_window\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Camshift is a colorbased tracker so we first set up the ROI. \u001b[39;00m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# ROI is basically the cropped image of the selcted object's window.\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     roi\u001b[38;5;241m=\u001b[39m frame[y:y\u001b[38;5;241m+\u001b[39mh, x:x\u001b[38;5;241m+\u001b[39mw]\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "source": [
    "# check if 2nd point is also saved and then initialize the tracker according to the selected object.\n",
    "\n",
    "hsv= cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "if second_point_saved:\n",
    "    \n",
    "    roi_hist, roi= initializeTracker(frame, windowName)\n",
    "    second_point_saved= False\n",
    "    can_track= True\n",
    "    \n",
    "# start tracking\n",
    "# If can_track is false but first_point is saved then it draws a circle wherever the mouse release event happens.\n",
    "if can_track:\n",
    "    \n",
    "    # finds the same color distribution of the ROI’s histogram in the current frame.\n",
    "    dst = cv2.calcBackProject([hsv], [0], roi_hist, [0, 180], 1)\n",
    "    \n",
    "    # apply camshift to get the new location\n",
    "    ret, track_window= cv2.CamShift(dst, track_window, term_crit)\n",
    "    \n",
    "    # After that call the cv2.CamShift() method to track the selected object. The method takes the Back projected histogram, track window (selected object’s window), \n",
    "    # and the term criteria as argument and returns the objects box information and updated track window\n",
    "    pts= cv2.boxPoints(ret)\n",
    "    pts= np.int0(pts)\n",
    "    print(ret)\n",
    "    \n",
    "    cv2.imshow('roi', roi)\n",
    "    output= cv2.polylines(frame, [pts], True, 255, 2)\n",
    "    \n",
    "else:\n",
    "    output= frame\n",
    "    if first_point_saved:\n",
    "        cv2.circle(output, (x,y), 5, (0,0,255), -1)\n",
    "        cv2.destroyAllWindows('roi')\n",
    "\n",
    "cv2.imshow(windowName, output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df25c18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5775dd04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041c598c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1897764",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672647c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3140acbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5cd272",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e7604d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fbd351",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06404c9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1074d6b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ceeac08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
